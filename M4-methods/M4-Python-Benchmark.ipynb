{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import seed\n",
    "seed(42)\n",
    "from tensorflow import set_random_seed\n",
    "set_random_seed(42)\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, SimpleRNN\n",
    "from keras.optimizers import rmsprop\n",
    "from keras import backend as ker\n",
    "from math import sqrt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import gc\n",
    "from sklearn.model_selection import train_test_split\n",
    "RANDOM_SEED= 40\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM, Dropout, Activation\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, SimpleRNN\n",
    "from keras.optimizers import rmsprop\n",
    "from keras import backend as ker\n",
    "\n",
    "def remov_nan (dataset):\n",
    "    '''\n",
    "    to remove all NaN Values in a \n",
    "    Time Serie Dataframe\n",
    "    '''\n",
    "    n = dataset.isnull().sum() \n",
    "    data = dataset[0:(len(dataset)-n)]\n",
    "    return data\n",
    "\n",
    "\n",
    "def detrend(insample_data):\n",
    "    \"\"\"\n",
    "    Calculates a & b parameters of LRL\n",
    "\n",
    "    :param insample_data:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    x = np.arange(len(insample_data))\n",
    "    a, b = np.polyfit(x, insample_data, 1)\n",
    "    return a, b\n",
    "\n",
    "\n",
    "def deseasonalize(original_ts, ppy):\n",
    "    \"\"\"\n",
    "    Calculates and returns seasonal indices\n",
    "\n",
    "    :param original_ts: original data\n",
    "    :param ppy: periods per year\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    # === get in-sample data\n",
    "    original_ts = original_ts[:-out_of_sample]\n",
    "    \"\"\"\n",
    "    if seasonality_test(original_ts, ppy):\n",
    "        # print(\"seasonal\")\n",
    "        # ==== get moving averages\n",
    "        ma_ts = moving_averages(original_ts, ppy)\n",
    "\n",
    "        # ==== get seasonality indices\n",
    "        le_ts = original_ts * 100 / ma_ts\n",
    "        le_ts = np.hstack((le_ts, np.full((ppy - (len(le_ts) % ppy)), np.nan)))\n",
    "        le_ts = np.reshape(le_ts, (-1, ppy))\n",
    "        si = np.nanmean(le_ts, 0)\n",
    "        norm = np.sum(si) / (ppy * 100)\n",
    "        si = si / norm\n",
    "    else:\n",
    "        # print(\"NOT seasonal\")\n",
    "        si = np.full(ppy, 100)\n",
    "\n",
    "    return si\n",
    "\n",
    "\n",
    "def moving_averages(ts_init, window):\n",
    "    \"\"\"\n",
    "    Calculates the moving averages for a given TS\n",
    "\n",
    "    :param ts_init: the original time series\n",
    "    :param window: window length\n",
    "    :return: moving averages ts\n",
    "    \"\"\"\n",
    "    if len(ts_init) % 2 == 0:\n",
    "        ts_ma = pd.rolling_mean(ts_init, window, center=True)\n",
    "        ts_ma = pd.rolling_mean(ts_ma, 2, center=True)\n",
    "        ts_ma = np.roll(ts_ma, -1)\n",
    "    else:\n",
    "        ts_ma = pd.rolling_mean(ts_init, window, center=True)\n",
    "\n",
    "    return ts_ma\n",
    "\n",
    "\n",
    "def seasonality_test(original_ts, ppy):\n",
    "    \"\"\"\n",
    "    Seasonality test\n",
    "\n",
    "    :param original_ts: time series\n",
    "    :param ppy: periods per year\n",
    "    :return: boolean value: whether the TS is seasonal\n",
    "    \"\"\"\n",
    "    s = acf(original_ts, 1)\n",
    "    for i in range(2, ppy):\n",
    "        s = s + (acf(original_ts, i) ** 2)\n",
    "\n",
    "    limit = 1.645 * (sqrt((1 + 2 * s) / len(original_ts)))\n",
    "\n",
    "    return (abs(acf(original_ts, ppy))) > limit\n",
    "\n",
    "\n",
    "def acf(data, k):\n",
    "    \"\"\"\n",
    "    Autocorrelation function\n",
    "\n",
    "    :param data: time series\n",
    "    :param k: lag\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    m = np.mean(data)\n",
    "    s1 = 0\n",
    "    for i in range(k, len(data)):\n",
    "        s1 = s1 + ((data[i] - m) * (data[i - k] - m))\n",
    "\n",
    "    s2 = 0\n",
    "    for i in range(0, len(data)):\n",
    "        s2 = s2 + ((data[i] - m) ** 2)\n",
    "\n",
    "    return float(s1 / s2)\n",
    "\n",
    "def windows_for_forecasts(data, in_num, fh):\n",
    "    \"\"\"\n",
    "    Splits the series into train and test sets. Each step takes multiple points as inputs\n",
    "    \"\"\"\n",
    "    x_train, y_train = data[:-1], np.roll(data, -in_num)[:-in_num]\n",
    "\n",
    "\n",
    "    # reshape input to be [samples, time steps, features] (N-NF samples, 1 time step, 1 feature)\n",
    "    x_train = np.reshape(x_train, (-1, 1))\n",
    "  \n",
    "    temp_train = np.roll(x_train, -1)\n",
    "    for x in range(1, in_num):\n",
    "        x_train = np.concatenate((x_train[:-1], temp_train[:-1]), 1)\n",
    "        temp_train = np.roll(temp_train, -1)[:-1]\n",
    "\n",
    "    return x_train, y_train\n",
    "\n",
    "\n",
    "\n",
    "def split_into_train_test(data, in_num, fh):\n",
    "    \"\"\"\n",
    "    Splits the series into train and test sets. Each step takes multiple points as inputs\n",
    "\n",
    "    :param data: an individual TS\n",
    "    :param fh: number of out of sample points\n",
    "    :param in_num: number of input points for the forecast\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    train, test = data[:-fh], data[-(fh + in_num):]\n",
    "    x_train, y_train = train[:-1], np.roll(train, -in_num)[:-in_num]\n",
    "    x_test, y_test = train[-in_num:], np.roll(test, -in_num)[:-in_num]\n",
    "\n",
    "    # reshape input to be [samples, time steps, features] (N-NF samples, 1 time step, 1 feature)\n",
    "    x_train = np.reshape(x_train, (-1, 1))\n",
    "    x_test = np.reshape(x_test, (-1, 1))\n",
    "    temp_test = np.roll(x_test, -1)\n",
    "    temp_train = np.roll(x_train, -1)\n",
    "    for x in range(1, in_num):\n",
    "        x_train = np.concatenate((x_train[:-1], temp_train[:-1]), 1)\n",
    "        x_test = np.concatenate((x_test[:-1], temp_test[:-1]), 1)\n",
    "        temp_test = np.roll(temp_test, -1)[:-1]\n",
    "        temp_train = np.roll(temp_train, -1)[:-1]\n",
    "\n",
    "    return x_train, y_train, x_test, y_test\n",
    "\n",
    "\n",
    "def rnn_bench(x_train, y_train, x_test, fh, input_size):\n",
    "    \"\"\"\n",
    "    Forecasts using 6 SimpleRNN nodes in the hidden layer and a Dense output layer\n",
    "\n",
    "    :param x_train: train data\n",
    "    :param y_train: target values for training\n",
    "    :param x_test: test data\n",
    "    :param fh: forecasting horizon\n",
    "    :param input_size: number of points used as input\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    # reshape to match expected input\n",
    "    x_train = np.reshape(x_train, (-1, input_size, 1))\n",
    "    x_test = np.reshape(x_test, (-1, input_size, 1))\n",
    "\n",
    "    # create the model\n",
    "    model = Sequential([\n",
    "        SimpleRNN(6, input_shape=(input_size, 1), activation='linear',\n",
    "                  use_bias=False, kernel_initializer='glorot_uniform',\n",
    "                  recurrent_initializer='orthogonal', bias_initializer='zeros',\n",
    "                  dropout=0.0, recurrent_dropout=0.0),\n",
    "        Dense(1, use_bias=True, activation='linear')\n",
    "    ])\n",
    "    opt = rmsprop(lr=0.001)\n",
    "    model.compile(loss='mean_squared_error', optimizer=opt)\n",
    "\n",
    "    # fit the model to the training data\n",
    "    model.fit(x_train, y_train, epochs=1000, batch_size=100)\n",
    "   # model.fit(x_train, y_train, epochs=100, batch_size=1, verbose=0)\n",
    "\n",
    "    # make predictions\n",
    "    y_hat_test = []\n",
    "    last_prediction = model.predict(x_test)[0]\n",
    "    for i in range(0, fh):\n",
    "        y_hat_test.append(last_prediction)\n",
    "        x_test[0] = np.roll(x_test[0], -1)\n",
    "        x_test[0, (len(x_test[0]) - 1)] = last_prediction\n",
    "        last_prediction = model.predict(x_test)[0]\n",
    "\n",
    "    return np.asarray(y_hat_test)\n",
    "\n",
    "\n",
    "def mlp_bench(x_train, y_train, x_test, fh):\n",
    "    \"\"\"\n",
    "    Forecasts using a simple MLP which 6 nodes in the hidden layer\n",
    "\n",
    "    :param x_train: train input data\n",
    "    :param y_train: target values for training\n",
    "    :param x_test: test data\n",
    "    :param fh: forecasting horizon\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    y_hat_test = []\n",
    "\n",
    "    model = MLPRegressor(hidden_layer_sizes=6, activation='identity', solver='adam',\n",
    "                         max_iter=100, learning_rate='adaptive', learning_rate_init=0.001,\n",
    "                         random_state=42)\n",
    "    model.fit(x_train, y_train)\n",
    "\n",
    "    last_prediction = model.predict(x_test)[0]\n",
    "    for i in range(0, fh):\n",
    "        y_hat_test.append(last_prediction)\n",
    "        x_test[0] = np.roll(x_test[0], -1)\n",
    "        x_test[0, (len(x_test[0]) - 1)] = last_prediction\n",
    "        last_prediction = model.predict(x_test)[0]\n",
    "\n",
    "    return np.asarray(y_hat_test)\n",
    "\n",
    "\n",
    "   \n",
    "\n",
    "\n",
    "\n",
    "def smape(a, b):\n",
    "    \"\"\"\n",
    "    Calculates sMAPE\n",
    "\n",
    "    :param a: actual values\n",
    "    :param b: predicted values\n",
    "    :return: sMAPE\n",
    "    \"\"\"\n",
    "    a = np.reshape(a, (-1,))\n",
    "    b = np.reshape(b, (-1,))\n",
    "    return np.mean(2.0 * np.abs(a - b) / (np.abs(a) + np.abs(b))).item()\n",
    "\n",
    "\n",
    "def mase(insample, y_test, y_hat_test, freq):\n",
    "    \"\"\"\n",
    "    Calculates MAsE\n",
    "\n",
    "    :param insample: insample data\n",
    "    :param y_test: out of sample target values\n",
    "    :param y_hat_test: predicted values\n",
    "    :param freq: data frequency\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    y_hat_naive = []\n",
    "    for i in range(freq, len(insample)):\n",
    "        y_hat_naive.append(insample[(i - freq)])\n",
    "\n",
    "    masep = np.mean(abs(insample[freq:] - y_hat_naive))\n",
    "\n",
    "    return np.mean(abs(y_test - y_hat_test)) / masep\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "def main(data_path,fh,freq,df,series_type,forecasts_path):\n",
    "    print('Prepare Data')\n",
    "    data_all=pd.read_csv(data_path, skiprows=0, index_col =0)\n",
    "    in_size = 5    # number of points used as input for each forecast\n",
    "\n",
    "    err_RNN_sMAPE = []\n",
    "    err_RNN_MASE = []\n",
    "    \n",
    "\n",
    "    \n",
    "    counter = 0\n",
    "    # ===== Main loop which goes through all timeseries =====\n",
    "    for j in range(len(data_all)):\n",
    "        start = time.time()\n",
    "        \n",
    "        \n",
    "        ts = data_all.iloc[j, :]\n",
    "        ts = remov_nan(ts)\n",
    "\n",
    "        # remove seasonality\n",
    "        seasonality_in = deseasonalize(ts, freq)\n",
    "\n",
    "        for i in range(0, len(ts)):\n",
    "            ts[i] = ts[i] * 100 / seasonality_in[i % freq]\n",
    "\n",
    "        # detrending\n",
    "        a, b = detrend(ts)\n",
    "\n",
    "        for i in range(0, len(ts)):\n",
    "            ts[i] = ts[i] - ((a * i) + b)\n",
    "\n",
    "        x_train, y_train = windows_for_forecasts(ts, in_size, fh)\n",
    "        \n",
    "        \n",
    "       \n",
    "        # RNN benchmark - Produce forecasts\n",
    "        print('Train LSTM')\n",
    "        #y_hat_test_RNN = np.reshape(rnn_bench(x_train, y_train, x_test, fh, in_size), (-1))\n",
    "        windowForForecast=ts[len(ts)-in_size:]\n",
    "        print('windowForForecast',windowForForecast.shape)\n",
    "        y_hat_test_RNN=LSTM_NN(x_train, y_train, windowForForecast, fh, in_size)\n",
    "        y_hat_test_RNN = np.reshape(y_hat_test_RNN, (-1))\n",
    "\n",
    "        print('series_type',series_type)\n",
    "        df.iloc[j,0]=str(series_type[0])+str(j)\n",
    "        print('y_hat_test_RNN',y_hat_test_RNN)\n",
    "        print('y_hat_test_RNN shape',y_hat_test_RNN.shape)\n",
    "        print('df shape',df.iloc[j].shape)\n",
    "        df.iloc[j,1:(len(y_hat_test_RNN)+1)]=y_hat_test_RNN\n",
    "        df.to_csv(forecasts_path, index=False)\n",
    "        print('Test Models')\n",
    "     \n",
    "\n",
    "        # add trend\n",
    "        for i in range(0, len(ts)):\n",
    "            ts[i] = ts[i] + ((a * i) + b)\n",
    "\n",
    "        for i in range(0, fh):\n",
    "            #y_hat_test_MLP[i] = y_hat_test_MLP[i] + ((a * (len(ts) + i + 1)) + b)\n",
    "            y_hat_test_RNN[i] = y_hat_test_RNN[i] + ((a * (len(ts) + i + 1)) + b)\n",
    "\n",
    "        # add seasonality\n",
    "        for i in range(0, len(ts)):\n",
    "            ts[i] = ts[i] * seasonality_in[i % freq] / 100\n",
    "\n",
    "        for i in range(len(ts), len(ts) + fh):\n",
    "            y_hat_test_RNN[i - len(ts)] = y_hat_test_RNN[i - len(ts)] * seasonality_in[i % freq] / 100\n",
    "\n",
    "        # check if negative or extreme\n",
    "        for i in range(len(y_hat_test_RNN)):\n",
    "       \n",
    "            if y_hat_test_RNN[i] < 0:\n",
    "                y_hat_test_RNN[i] = 0\n",
    "                \n",
    "            \n",
    "            if y_hat_test_RNN[i] > (1000 * max(ts)):\n",
    "                y_hat_test_RNN[i] = max(ts)\n",
    "\n",
    "    return y_hat_test_RNN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "def LSTM_NN(x_train, y_train, x_test, fh, in_back):\n",
    "\n",
    "    \n",
    "    \n",
    "    # reshape to match expected input\n",
    "    x_train = np.reshape(x_train, (-1, in_back, 1))\n",
    "    x_test = np.reshape(x_test, (-1, in_back, 1))\n",
    "      \n",
    "     # create the model and parametrize it\n",
    "    model = Sequential()\n",
    "    \n",
    "    #model.add(LSTM(input_shape=(in_back,1),output_dim=100,return_sequences=True))\n",
    "    #model.add(LSTM(input_shape=(in_back,1),output_dim=50,return_sequences=True))\n",
    "\n",
    "    model.add(LSTM(input_shape=(in_back,1),units=512))\n",
    "    #model.add(LSTM(512))\n",
    "\n",
    "\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Activation('linear'))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "    # fit the model to the training data\n",
    "    early_stopping_monitor = EarlyStopping(monitor='loss', mode='min',patience=4)\n",
    "\n",
    "    model.fit(x_train, y_train, epochs=1500, batch_size=200,callbacks=[early_stopping_monitor],verbose=0)\n",
    "    #model.fit(x_train, y_train, epochs=100, batch_size=1, verbose=0)\n",
    "    \n",
    "\n",
    "    # make predictions\n",
    "    y_hat_test = []\n",
    "    last_prediction = model.predict(x_test)[0]\n",
    "    for i in range(0, fh):\n",
    "        y_hat_test.append(last_prediction)\n",
    "        x_test[0] = np.roll(x_test[0], -1)\n",
    "        x_test[0, (len(x_test[0]) - 1)] = last_prediction\n",
    "        last_prediction = model.predict(x_test)[0]\n",
    "    \n",
    "    forecast = []\n",
    "    \n",
    "\n",
    "\n",
    "    return np.asarray(y_hat_test)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Daily\n",
      "Prepare Data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/anaconda3/envs/jupyter/lib/python3.6/site-packages/ipykernel_launcher.py:92: FutureWarning: pd.rolling_mean is deprecated for Series and will be removed in a future version, replace with \n",
      "\tSeries.rolling(window=1,center=True).mean()\n",
      "/home/jupyter/anaconda3/envs/jupyter/lib/python3.6/site-packages/numpy/core/fromnumeric.py:52: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n",
      "  return getattr(obj, method)(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train LSTM\n",
      "windowForForecast (5,)\n",
      "series_type Daily\n",
      "y_hat_test_RNN [939.0928  937.1328  935.7594  934.28033 932.8767  931.50525 930.22485\n",
      " 929.039   927.9828  927.04895 926.22815 925.54755 924.9829  924.5196 ]\n",
      "y_hat_test_RNN shape (14,)\n",
      "df shape (49,)\n",
      "Test Models\n",
      "Train LSTM\n",
      "windowForForecast (5,)\n",
      "series_type Daily\n",
      "y_hat_test_RNN [411.51938 385.9243  432.64078 491.6146  513.24005 472.46765 454.9778\n",
      " 445.74927 433.24213 424.82272 427.32288 454.21292 480.77533 481.98785]\n",
      "y_hat_test_RNN shape (14,)\n",
      "df shape (49,)\n",
      "Test Models\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/anaconda3/envs/jupyter/lib/python3.6/site-packages/ipykernel_launcher.py:88: FutureWarning: pd.rolling_mean is deprecated for Series and will be removed in a future version, replace with \n",
      "\tSeries.rolling(window=1,center=True).mean()\n",
      "/home/jupyter/anaconda3/envs/jupyter/lib/python3.6/site-packages/ipykernel_launcher.py:89: FutureWarning: pd.rolling_mean is deprecated for Series and will be removed in a future version, replace with \n",
      "\tSeries.rolling(window=2,center=True).mean()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train LSTM\n",
      "windowForForecast (5,)\n",
      "series_type Daily\n",
      "y_hat_test_RNN [714.983   689.9539  684.31726 681.1625  678.4194  677.0754  676.32654\n",
      " 675.83154 675.5052  675.29675 675.16437 675.08057 675.0278  674.99445]\n",
      "y_hat_test_RNN shape (14,)\n",
      "df shape (49,)\n",
      "Test Models\n",
      "Train LSTM\n",
      "windowForForecast (5,)\n",
      "series_type Daily\n",
      "y_hat_test_RNN [491.48785 485.8333  483.0422  481.74847 481.0738  480.69873 480.48038\n",
      " 480.35342 480.27835 480.2326  480.2048  480.18774 480.1774  480.171  ]\n",
      "y_hat_test_RNN shape (14,)\n",
      "df shape (49,)\n",
      "Test Models\n",
      "Train LSTM\n",
      "windowForForecast (5,)\n",
      "series_type Daily\n",
      "y_hat_test_RNN [-291.63025 -294.69022 -296.31787 -297.20218 -297.7425  -298.15338\n",
      " -298.5008  -298.8117  -299.093   -299.34772 -299.58145 -299.80005\n",
      " -300.00464 -300.19653]\n",
      "y_hat_test_RNN shape (14,)\n",
      "df shape (49,)\n",
      "Test Models\n",
      "Train LSTM\n",
      "windowForForecast (5,)\n",
      "series_type Daily\n",
      "y_hat_test_RNN [-111.07876  -105.14586   -99.94797   -94.17185   -87.62311   -80.885155\n",
      "  -75.047325  -69.19708   -62.818283  -55.698326  -46.85789   -32.37626\n",
      "   12.485272   93.65365 ]\n",
      "y_hat_test_RNN shape (14,)\n",
      "df shape (49,)\n",
      "Test Models\n",
      "Train LSTM\n",
      "windowForForecast (5,)\n",
      "series_type Daily\n",
      "y_hat_test_RNN [2746.922  2711.2903 2674.9087 2626.7637 2617.3853 2613.366  2607.5828\n",
      " 2604.0237 2601.7686 2599.1016 2597.0015 2595.396  2593.7288 2592.328 ]\n",
      "y_hat_test_RNN shape (14,)\n",
      "df shape (49,)\n",
      "Test Models\n",
      "Train LSTM\n",
      "windowForForecast (5,)\n",
      "series_type Daily\n",
      "y_hat_test_RNN [173.27039 168.34987 169.91193 169.77756 169.57141 169.78886 169.82692\n",
      " 169.82182 169.82402 169.8252  169.82503 169.82498 169.82501 169.825  ]\n",
      "y_hat_test_RNN shape (14,)\n",
      "df shape (49,)\n",
      "Test Models\n",
      "Train LSTM\n",
      "windowForForecast (5,)\n",
      "series_type Daily\n",
      "y_hat_test_RNN [ 34.061985   21.506136   12.315917   -4.0289536 -11.367934  -14.488346\n",
      " -37.013645  -19.12357   -14.039718    6.6393924  13.632827   -4.541817\n",
      "   3.9549468 -13.592197 ]\n",
      "y_hat_test_RNN shape (14,)\n",
      "df shape (49,)\n",
      "Test Models\n",
      "Train LSTM\n",
      "windowForForecast (5,)\n",
      "series_type Daily\n",
      "y_hat_test_RNN [-75.10019  -69.17656  -65.60134  -63.214096 -61.499107 -60.264343\n",
      " -59.42193  -58.864254 -58.506145 -58.281715 -58.142685 -58.05693\n",
      " -58.004295 -57.97199 ]\n",
      "y_hat_test_RNN shape (14,)\n",
      "df shape (49,)\n",
      "Test Models\n",
      "Train LSTM\n",
      "windowForForecast (5,)\n",
      "series_type Daily\n",
      "y_hat_test_RNN [2301.3499 2260.8423 2239.9512 2228.0674 2220.2961 2215.3403 2212.0305\n",
      " 2209.8628 2208.354  2207.3167 2206.6067 2206.1223 2205.7932 2205.57  ]\n",
      "y_hat_test_RNN shape (14,)\n",
      "df shape (49,)\n",
      "Test Models\n",
      "Train LSTM\n",
      "windowForForecast (5,)\n",
      "series_type Daily\n",
      "y_hat_test_RNN [65.14747  68.83061  63.348423 57.921215 52.31012  46.13006  40.85123\n",
      " 36.893265 34.496475 33.282887 32.92911  32.94255  32.844738 32.453106]\n",
      "y_hat_test_RNN shape (14,)\n",
      "df shape (49,)\n",
      "Test Models\n",
      "Train LSTM\n",
      "windowForForecast (5,)\n",
      "series_type Daily\n",
      "y_hat_test_RNN [-53.320366 -49.45129  -45.841465 -42.11189  -36.030083 -27.063623\n",
      " -14.054982   2.746573  18.145226  21.803844  20.8217    30.237171\n",
      "  55.225986  81.054405]\n",
      "y_hat_test_RNN shape (14,)\n",
      "df shape (49,)\n",
      "Test Models\n",
      "Train LSTM\n",
      "windowForForecast (5,)\n",
      "series_type Daily\n",
      "y_hat_test_RNN [-781.177   -776.70245 -763.0759  -753.9398  -751.80457 -751.81146\n",
      " -752.81384 -754.0118  -754.8661  -755.21716 -755.1957  -755.0064\n",
      " -754.80994 -754.6835 ]\n",
      "y_hat_test_RNN shape (14,)\n",
      "df shape (49,)\n",
      "Test Models\n",
      "Train LSTM\n",
      "windowForForecast (5,)\n",
      "series_type Daily\n",
      "y_hat_test_RNN [-10.474236 -25.61622  -37.359882 -41.70258  -38.951595 -40.5022\n",
      " -41.53644  -41.31428  -41.078594 -41.364136 -41.357906 -41.25647\n",
      " -41.26323  -41.284492]\n",
      "y_hat_test_RNN shape (14,)\n",
      "df shape (49,)\n",
      "Test Models\n",
      "Train LSTM\n",
      "windowForForecast (5,)\n",
      "series_type Daily\n",
      "y_hat_test_RNN [-218.35915 -217.7685  -217.45251 -217.4307  -217.33162 -217.41905\n",
      " -217.42384 -217.42374 -217.42406 -217.42413 -217.42406 -217.42406\n",
      " -217.42406 -217.42406]\n",
      "y_hat_test_RNN shape (14,)\n",
      "df shape (49,)\n",
      "Test Models\n",
      "Train LSTM\n",
      "windowForForecast (5,)\n",
      "series_type Daily\n",
      "y_hat_test_RNN [-92.5575   -94.488884 -93.741295 -92.54737  -90.29489  -89.71611\n",
      " -88.50254  -87.01099  -85.43679  -83.56973  -81.129    -77.94213\n",
      " -73.759674 -68.78593 ]\n",
      "y_hat_test_RNN shape (14,)\n",
      "df shape (49,)\n",
      "Test Models\n",
      "Train LSTM\n",
      "windowForForecast (5,)\n",
      "series_type Daily\n",
      "y_hat_test_RNN [ 66.405655   53.336754   53.693382   54.920155   54.220528   30.71569\n",
      "  -6.3705845 -25.509138  -42.21981   -39.918056  -31.33006    12.698062\n",
      "  21.873074  -14.733813 ]\n",
      "y_hat_test_RNN shape (14,)\n",
      "df shape (49,)\n",
      "Test Models\n",
      "Train LSTM\n",
      "windowForForecast (5,)\n",
      "series_type Daily\n",
      "y_hat_test_RNN [196.20422 196.65146 196.45471 196.40648 196.35544 196.3221  196.32077\n",
      " 196.32037 196.32027 196.32027 196.32027 196.32027 196.32027 196.32027]\n",
      "y_hat_test_RNN shape (14,)\n",
      "df shape (49,)\n",
      "Test Models\n",
      "Train LSTM\n",
      "windowForForecast (5,)\n",
      "series_type Daily\n",
      "y_hat_test_RNN [371.3218  361.66437 352.388   330.82516 314.34375 286.52386 247.86838\n",
      " 207.43994 165.57765 127.22053 119.71857 126.81752 145.42947 150.55489]\n",
      "y_hat_test_RNN shape (14,)\n",
      "df shape (49,)\n",
      "Test Models\n",
      "Weekly\n",
      "Prepare Data\n",
      "Train LSTM\n",
      "windowForForecast (5,)\n",
      "series_type Weekly\n",
      "y_hat_test_RNN [-521.58026 -506.52432 -497.84006 -493.53632 -492.02728 -490.68652\n",
      " -489.49542 -488.7042  -488.1787  -487.79385 -487.51324 -487.31555\n",
      " -487.17752]\n",
      "y_hat_test_RNN shape (13,)\n",
      "df shape (49,)\n",
      "Test Models\n",
      "Train LSTM\n",
      "windowForForecast (5,)\n",
      "series_type Weekly\n",
      "y_hat_test_RNN [ 255.13068   215.93712   140.54742    68.36058    13.23441   -60.540993\n",
      " -133.31664  -211.87923  -275.70255  -278.44812  -254.24504  -229.96501\n",
      " -189.00453 ]\n",
      "y_hat_test_RNN shape (13,)\n",
      "df shape (49,)\n",
      "Test Models\n",
      "Train LSTM\n",
      "windowForForecast (5,)\n",
      "series_type Weekly\n",
      "y_hat_test_RNN [-414.25052 -415.2093  -414.80365 -408.07874 -396.65796 -397.68906\n",
      " -396.24585 -394.8138  -394.91046 -394.48505 -394.28024 -394.25967\n",
      " -394.1562 ]\n",
      "y_hat_test_RNN shape (13,)\n",
      "df shape (49,)\n",
      "Test Models\n",
      "Train LSTM\n",
      "windowForForecast (5,)\n",
      "series_type Weekly\n",
      "y_hat_test_RNN [1539.2412 1526.4724 1527.9718 1525.1711 1525.4238 1524.753  1524.567\n",
      " 1524.5555 1524.5155 1524.5054 1524.5032 1524.5007 1524.5   ]\n",
      "y_hat_test_RNN shape (13,)\n",
      "df shape (49,)\n",
      "Test Models\n",
      "Train LSTM\n",
      "windowForForecast (5,)\n",
      "series_type Weekly\n",
      "y_hat_test_RNN [  45.475674    61.79947    -83.23951     52.265076  -137.0334\n",
      "  -37.74063   -111.089874    -3.6323612 -119.1988      36.79945\n",
      "   16.833458    56.552162   -20.918705 ]\n",
      "y_hat_test_RNN shape (13,)\n",
      "df shape (49,)\n",
      "Test Models\n",
      "Train LSTM\n",
      "windowForForecast (5,)\n",
      "series_type Weekly\n",
      "y_hat_test_RNN [-634.7452  -629.3776  -625.1161  -622.7392  -615.62585 -610.95483\n",
      " -606.2857  -600.8991  -594.9297  -588.2997  -580.9193  -573.0771\n",
      " -565.0658 ]\n",
      "y_hat_test_RNN shape (13,)\n",
      "df shape (49,)\n",
      "Test Models\n",
      "Train LSTM\n",
      "windowForForecast (5,)\n",
      "series_type Weekly\n",
      "y_hat_test_RNN [-457.252   -484.59436 -518.0391  -519.3741  -518.38275 -520.3321\n",
      " -519.7119  -519.85175 -519.8783  -519.8304  -519.8537  -519.8473\n",
      " -519.8474 ]\n",
      "y_hat_test_RNN shape (13,)\n",
      "df shape (49,)\n",
      "Test Models\n",
      "Train LSTM\n",
      "windowForForecast (5,)\n",
      "series_type Weekly\n",
      "y_hat_test_RNN [-274.82407 -280.14304 -281.27448 -282.5671  -281.41266 -280.99814\n",
      " -280.78354 -280.67346 -280.58447 -280.52597 -280.4877  -280.46298\n",
      " -280.4466 ]\n",
      "y_hat_test_RNN shape (13,)\n",
      "df shape (49,)\n",
      "Test Models\n",
      "Train LSTM\n",
      "windowForForecast (5,)\n",
      "series_type Weekly\n",
      "y_hat_test_RNN [324.68683 302.58096 291.51102 289.3174  295.31644 304.6217  311.02884\n",
      " 312.1     309.1589  304.74847 301.45782 300.78406 302.6939 ]\n",
      "y_hat_test_RNN shape (13,)\n",
      "df shape (49,)\n",
      "Test Models\n",
      "Train LSTM\n",
      "windowForForecast (5,)\n",
      "series_type Weekly\n",
      "y_hat_test_RNN [404.21194 413.94928 420.92996 425.24738 427.48605 428.75735 429.5123\n",
      " 429.949   430.20526 430.35657 430.4456  430.49808 430.52908]\n",
      "y_hat_test_RNN shape (13,)\n",
      "df shape (49,)\n",
      "Test Models\n",
      "Train LSTM\n",
      "windowForForecast (5,)\n",
      "series_type Weekly\n",
      "y_hat_test_RNN [-1529.3435 -1488.3035 -1370.8723 -1378.6998 -1278.5936 -1288.1094\n",
      " -1304.1218 -1361.7664 -1437.9016 -1475.6403 -1478.3212 -1440.0833\n",
      " -1373.7246]\n",
      "y_hat_test_RNN shape (13,)\n",
      "df shape (49,)\n",
      "Test Models\n",
      "Train LSTM\n",
      "windowForForecast (5,)\n",
      "series_type Weekly\n",
      "y_hat_test_RNN [-1763.712  -1754.6594 -1751.5212 -1749.7997 -1748.099  -1747.3947\n",
      " -1746.9373 -1746.6172 -1746.4272 -1746.3154 -1746.243  -1746.1981\n",
      " -1746.171 ]\n",
      "y_hat_test_RNN shape (13,)\n",
      "df shape (49,)\n",
      "Test Models\n",
      "Train LSTM\n",
      "windowForForecast (5,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "series_type Weekly\n",
      "y_hat_test_RNN [-154.75174  -117.38814    40.474674 -216.87134  -280.13315  -295.51263\n",
      " -218.93567  -236.70245  -207.50093  -245.81444  -287.01382  -297.23654\n",
      " -296.16495 ]\n",
      "y_hat_test_RNN shape (13,)\n",
      "df shape (49,)\n",
      "Test Models\n",
      "Train LSTM\n",
      "windowForForecast (5,)\n",
      "series_type Weekly\n",
      "y_hat_test_RNN [-90.30958  -90.91996  -91.234314 -91.40989  -91.48051  -91.51156\n",
      " -91.52344  -91.52746  -91.528366 -91.52842  -91.52825  -91.52808\n",
      " -91.52798 ]\n",
      "y_hat_test_RNN shape (13,)\n",
      "df shape (49,)\n",
      "Test Models\n",
      "Train LSTM\n",
      "windowForForecast (5,)\n",
      "series_type Weekly\n",
      "y_hat_test_RNN [333.60468 327.7811  322.79993 318.09576 314.47693 313.34103 312.3084\n",
      " 311.69568 311.27798 311.01517 310.8382  310.72314 310.64713]\n",
      "y_hat_test_RNN shape (13,)\n",
      "df shape (49,)\n",
      "Test Models\n",
      "Train LSTM\n",
      "windowForForecast (5,)\n",
      "series_type Weekly\n",
      "y_hat_test_RNN [-530.6605  -528.87476 -555.20496 -558.73834 -569.33905 -577.2938\n",
      " -587.24603 -595.5202  -604.264   -611.3578  -616.3251  -619.4459\n",
      " -621.2936 ]\n",
      "y_hat_test_RNN shape (13,)\n",
      "df shape (49,)\n",
      "Test Models\n",
      "Train LSTM\n",
      "windowForForecast (5,)\n",
      "series_type Weekly\n",
      "y_hat_test_RNN [-1211.2446 -1198.2256 -1184.9786 -1167.7668 -1152.0704 -1141.924\n",
      " -1133.6963 -1126.4049 -1119.2766 -1111.8065 -1103.5552 -1093.3914\n",
      " -1079.9376]\n",
      "y_hat_test_RNN shape (13,)\n",
      "df shape (49,)\n",
      "Test Models\n",
      "Train LSTM\n",
      "windowForForecast (5,)\n",
      "series_type Weekly\n",
      "y_hat_test_RNN [33.25279  33.16907  30.473423 33.939884 34.25823  19.458384 20.12471\n",
      " 19.49252  26.051605 26.646877 13.766014 15.068794 14.264066]\n",
      "y_hat_test_RNN shape (13,)\n",
      "df shape (49,)\n",
      "Test Models\n",
      "Train LSTM\n",
      "windowForForecast (5,)\n",
      "series_type Weekly\n",
      "y_hat_test_RNN [1131.4093  1123.29    1120.652   1099.112   1054.9409  1036.6056\n",
      " 1034.1115  1028.8204  1018.04913 1010.19104 1008.42664 1005.4633\n",
      "  997.35187]\n",
      "y_hat_test_RNN shape (13,)\n",
      "df shape (49,)\n",
      "Test Models\n",
      "Train LSTM\n",
      "windowForForecast (5,)\n",
      "series_type Weekly\n",
      "y_hat_test_RNN [ 38.164207 -17.616083  92.16866   77.48191  -33.545513  69.26644\n",
      "  86.1033    65.715935 -21.67137  108.56632   87.256935  72.94827\n",
      "   9.548652]\n",
      "y_hat_test_RNN shape (13,)\n",
      "df shape (49,)\n",
      "Test Models\n",
      "Hourly\n",
      "Prepare Data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/anaconda3/envs/jupyter/lib/python3.6/site-packages/ipykernel_launcher.py:88: FutureWarning: pd.rolling_mean is deprecated for Series and will be removed in a future version, replace with \n",
      "\tSeries.rolling(window=24,center=True).mean()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train LSTM\n",
      "windowForForecast (5,)\n",
      "series_type Hourly\n",
      "y_hat_test_RNN [ 0.10128693  0.08987233  0.07184206  0.05467306  0.04167884  0.02998592\n",
      "  0.02121497  0.01441608  0.00935679  0.00573167  0.00316408  0.00141875\n",
      "  0.00026424 -0.00046821 -0.00090783 -0.00115194 -0.00126914 -0.00130819\n",
      " -0.00130206 -0.00127246 -0.00123312 -0.00119224 -0.00115431 -0.00112145\n",
      " -0.00109432 -0.00107274 -0.0010561  -0.00104363 -0.00103452 -0.00102804\n",
      " -0.00102356 -0.00102055 -0.00101861 -0.00101741 -0.00101671 -0.00101635\n",
      " -0.0010162  -0.00101618 -0.00101622 -0.00101629 -0.00101638 -0.00101647\n",
      " -0.00101654 -0.00101661 -0.00101666 -0.0010167  -0.00101673 -0.00101675]\n",
      "y_hat_test_RNN shape (48,)\n",
      "df shape (49,)\n",
      "Test Models\n",
      "Train LSTM\n",
      "windowForForecast (5,)\n",
      "series_type Hourly\n",
      "y_hat_test_RNN [  3.2922022  -9.784897   -7.1771955  -7.0714355 -12.976571   -4.879099\n",
      "  -7.6134467  -4.277638   -3.1219985  -6.174265   -6.6096597  -8.095279\n",
      "  -6.180766   -7.3109994  -7.6652794  -7.7289553  -8.000294   -8.856921\n",
      "  -9.156777   -9.423516   -9.694164  -10.027848  -10.288126  -10.481435\n",
      " -10.65413   -10.768644  -10.829461  -10.869912  -10.894153  -10.901609\n",
      " -10.905371  -10.907524  -10.9055605 -10.904039  -10.903612  -10.901996\n",
      " -10.900942  -10.900862  -10.900266  -10.899859  -10.900001  -10.899857\n",
      " -10.899709  -10.899843  -10.899826  -10.899756  -10.899834  -10.89984  ]\n",
      "y_hat_test_RNN shape (48,)\n",
      "df shape (49,)\n",
      "Test Models\n",
      "Train LSTM\n",
      "windowForForecast (5,)\n",
      "series_type Hourly\n",
      "y_hat_test_RNN [-96.98355   -42.178       2.0777235  55.633774   66.45243    96.89633\n",
      " 130.90355   123.19717   113.64206   120.86522   126.41092    97.364136\n",
      " 103.99873    84.63436   105.62227    72.76722   105.07443   100.16503\n",
      " 119.70397   122.119896  122.12489   127.67936   128.09215   120.64017\n",
      " 114.22839   107.53474    85.73969    67.910095   41.307724   17.040096\n",
      "  17.468372  -18.846478  -30.679102  -20.430586   11.494052   45.11791\n",
      "  88.122086   58.28826     2.0701098 -58.656757  -95.879654  -52.697407\n",
      " -27.605366  -35.250095  -94.30834   -50.139877  -29.724503  -17.598158 ]\n",
      "y_hat_test_RNN shape (48,)\n",
      "df shape (49,)\n",
      "Test Models\n",
      "Train LSTM\n",
      "windowForForecast (5,)\n",
      "series_type Hourly\n",
      "y_hat_test_RNN [-44.716484 -43.543667 -45.194546 -44.5731   -42.19259  -41.057568\n",
      " -41.34696  -41.006123 -39.64634  -38.67248  -38.507584 -38.138023\n",
      " -37.16139  -36.32198  -35.985058 -35.596188 -34.840435 -34.136063\n",
      " -33.763565 -33.409542 -32.84003  -32.287457 -31.95138  -31.66093\n",
      " -31.249468 -30.843422 -30.581615 -30.370594 -30.09024  -29.800575\n",
      " -29.595667 -29.43254  -29.233229 -29.025475 -28.87022  -28.74746\n",
      " -28.606482 -28.457724 -28.339788 -28.24592  -28.144522 -28.037914\n",
      " -27.949528 -27.877806 -27.803274 -27.725101 -27.657888 -27.602713]\n",
      "y_hat_test_RNN shape (48,)\n",
      "df shape (49,)\n",
      "Test Models\n",
      "Train LSTM\n",
      "windowForForecast (5,)\n",
      "series_type Hourly\n",
      "y_hat_test_RNN [0.15055288 0.18982129 0.1905325  0.18286355 0.17772417 0.1589889\n",
      " 0.14520027 0.12757622 0.11109817 0.09619238 0.08178665 0.06962594\n",
      " 0.05865288 0.04933356 0.04144789 0.03477193 0.02929149 0.02475128\n",
      " 0.02106715 0.01809023 0.01570074 0.01380693 0.01231092 0.01114349\n",
      " 0.01023906 0.00954514 0.00901901 0.00862428 0.00833263 0.00812055\n",
      " 0.00796951 0.00786478 0.00779472 0.00775031 0.00772451 0.00771197\n",
      " 0.00770862 0.0077114  0.00771807 0.00772699 0.00773699 0.00774727\n",
      " 0.0077573  0.00776674 0.00777538 0.00778313 0.00778998 0.00779593]\n",
      "y_hat_test_RNN shape (48,)\n",
      "df shape (49,)\n",
      "Test Models\n",
      "Train LSTM\n",
      "windowForForecast (5,)\n",
      "series_type Hourly\n",
      "y_hat_test_RNN [-91.56728   -70.966156  -82.55739   -89.374985  -10.155419   59.136463\n",
      " 128.48346   133.8268    133.94992   109.8278     68.53723   106.18441\n",
      " 126.29491   127.293686  103.88883    68.5139     85.80519   125.99796\n",
      " 128.26443   115.763916   64.09602    58.609722  124.048965  127.19895\n",
      " 126.65013    53.332077   53.47352   123.366425  121.537964   42.083702\n",
      "  31.265526   95.76662   109.90719    34.53835     3.0099955  81.53906\n",
      " 117.71208    43.749348   -2.0707953  63.79919    15.685519  -33.27358\n",
      "  68.47969   -17.070925  -49.47665    13.133936  -53.85951   -97.53227  ]\n",
      "y_hat_test_RNN shape (48,)\n",
      "df shape (49,)\n",
      "Test Models\n",
      "Train LSTM\n",
      "windowForForecast (5,)\n",
      "series_type Hourly\n",
      "y_hat_test_RNN [ -86.17939    149.74533    197.67746    233.60406    237.08144\n",
      "  217.82495    111.52541     59.15699      0.9196868  -15.099836\n",
      "  -85.12775   -184.34337   -209.20935   -208.2668    -180.88193\n",
      " -179.55861   -169.16914    -89.974075    51.75049    200.65137\n",
      "  231.7647     236.31384    235.63783    101.97012     53.732853\n",
      "   -7.2714567   -8.380636   -97.466385  -196.03555   -211.72964\n",
      " -179.2928    -179.98315   -176.83095   -133.3496     -51.281548\n",
      "   10.0698595  126.32242    114.51815    117.913994   188.3706\n",
      "  149.30005    178.31577    151.91365    150.59094     89.55776\n",
      "   85.71449     72.8559     160.11514  ]\n",
      "y_hat_test_RNN shape (48,)\n",
      "df shape (49,)\n",
      "Test Models\n",
      "Train LSTM\n",
      "windowForForecast (5,)\n",
      "series_type Hourly\n",
      "y_hat_test_RNN [ 18.880781    17.24108     18.547016    13.81802     16.617779\n",
      "  24.79581     31.815857    40.12871     34.643963    27.574883\n",
      "  17.593336     8.058216     5.3371053    6.857695    -6.989002\n",
      "  -2.951627    -6.900864    -5.8556366   -4.739611    -0.8025911\n",
      "   6.4961996   14.245041    16.185339    14.0783       8.518156\n",
      "   8.696976    13.087135    22.898949    26.813765    29.320496\n",
      "  26.630312    22.800064    14.885537     4.955615    -2.2824492\n",
      " -12.971288   -18.720673   -23.253199   -12.375778    -2.9207473\n",
      "   0.89616156   3.4274414   -0.9408467   -0.26135918  -8.979446\n",
      " -13.03314    -20.047739   -10.005098  ]\n",
      "y_hat_test_RNN shape (48,)\n",
      "df shape (49,)\n",
      "Test Models\n",
      "Train LSTM\n",
      "windowForForecast (5,)\n",
      "series_type Hourly\n",
      "y_hat_test_RNN [ 0.06877703  0.16639286  0.22497453  0.25665274  0.26488036  0.24920906\n",
      "  0.2173028   0.17401913  0.1252928   0.07667737  0.03233402 -0.00459131\n",
      " -0.03235802 -0.05040211 -0.0591092  -0.05958344 -0.05336897 -0.04223284\n",
      " -0.02797896 -0.01230461  0.00330177  0.0176299   0.0297859   0.0392033\n",
      "  0.04563016  0.04909559  0.04986028  0.04835648  0.04512342  0.04074426\n",
      "  0.03578977  0.03077291  0.02611655  0.02213482  0.01902749  0.01688503\n",
      "  0.01570199  0.01539575  0.01582796  0.01682633  0.01820496  0.01978186\n",
      "  0.02139284  0.02290139  0.02420448  0.02523473  0.02595922  0.02637582]\n",
      "y_hat_test_RNN shape (48,)\n",
      "df shape (49,)\n",
      "Test Models\n",
      "Train LSTM\n",
      "windowForForecast (5,)\n",
      "series_type Hourly\n",
      "y_hat_test_RNN [-248.52504  -190.97461   -11.739404   98.26132   145.38544   255.1316\n",
      "  121.78512   -47.670727  -82.47758   -88.88183  -163.04576  -171.43987\n",
      " -253.9291   -257.7616   -258.70203  -248.75182  -218.1687    -48.91947\n",
      "   81.17025   151.67302   236.23767    96.099236  131.65747   101.49215\n",
      "  155.22655    84.98533    53.44931    74.905045  120.8561    174.51851\n",
      "  244.53041   194.58801   240.3934    187.05273   205.55725   121.56151\n",
      "  136.07925    56.025978   89.20336    74.86269   162.28294   202.81554\n",
      "  200.84851   228.99416   224.33507   230.3179    186.65837   180.32451 ]\n",
      "y_hat_test_RNN shape (48,)\n",
      "df shape (49,)\n",
      "Test Models\n",
      "Train LSTM\n",
      "windowForForecast (5,)\n",
      "series_type Hourly\n",
      "y_hat_test_RNN [ 77.06215    70.9138     65.56182    62.320747   61.152847   59.25775\n",
      "  56.240005   51.349377   43.73982    34.23955    26.024849   21.112986\n",
      "  13.550682    2.238785  -17.37167   -30.65546   -42.220966  -37.95984\n",
      " -55.402843  -63.483833  -63.514683  -56.227486  -46.154953  -27.301302\n",
      " -14.805377  -22.267157  -22.684748  -34.78025   -46.6519    -45.050793\n",
      " -48.429195  -49.896793  -43.763645  -29.360996   -9.245206    1.3411179\n",
      "  -1.137799  -15.625373  -21.414774  -41.039715  -52.77226   -76.91108\n",
      " -87.262184  -92.00829   -87.643326  -78.91906   -66.80879   -55.330284 ]\n",
      "y_hat_test_RNN shape (48,)\n",
      "df shape (49,)\n",
      "Test Models\n",
      "Train LSTM\n",
      "windowForForecast (5,)\n",
      "series_type Hourly\n",
      "y_hat_test_RNN [ -43.971653   -31.875782   -31.618454   -50.180397  -112.40714\n",
      " -194.56842   -256.99008   -200.94913   -137.33034    -78.03464\n",
      "  -29.59821      3.2090368    2.25597    -70.3123    -150.74913\n",
      " -203.23923   -142.68472    -79.0536     -21.275475    24.37622\n",
      "   42.506813   -31.080929   -41.68432   -109.769424  -179.70601\n",
      " -179.44186   -107.98247    -13.412581    50.455986    76.18621\n",
      "  119.41703    124.97287     71.24469      2.0953948  -73.570526\n",
      " -109.941826  -137.16449   -140.47859   -182.96838   -224.55586\n",
      " -267.67172   -273.1207    -232.21837   -196.07664   -176.8488\n",
      " -169.1187    -112.301605   -25.48748  ]\n",
      "y_hat_test_RNN shape (48,)\n",
      "df shape (49,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Models\n",
      "Train LSTM\n",
      "windowForForecast (5,)\n",
      "series_type Hourly\n",
      "y_hat_test_RNN [-0.5234884  -0.44243026 -0.3676501  -0.29629582 -0.2296117  -0.1641545\n",
      " -0.1015908  -0.04299693  0.01076633  0.05899804  0.10081639  0.13551207\n",
      "  0.16269624  0.18236731  0.19494194  0.20126249  0.20251858  0.20009716\n",
      "  0.19540428  0.18970208  0.18399273  0.17896567  0.17500512  0.17223942\n",
      "  0.17060989  0.16994126  0.17000248  0.17055292  0.17137362  0.17228517\n",
      "  0.17315516  0.17389804  0.17446966  0.17485933  0.17508031  0.1751609\n",
      "  0.17513639  0.17504296  0.17491321  0.17477353  0.17464308  0.17453387\n",
      "  0.17445168  0.17439735  0.17436823  0.17435963  0.17436604  0.17438194]\n",
      "y_hat_test_RNN shape (48,)\n",
      "df shape (49,)\n",
      "Test Models\n",
      "Train LSTM\n",
      "windowForForecast (5,)\n",
      "series_type Hourly\n",
      "y_hat_test_RNN [277.97754  251.15987  239.99629  236.95634  233.57387  238.44382\n",
      " 253.77312  269.07224  270.73312  252.43819  217.17871  170.98157\n",
      " 120.75188   72.69072   40.71114   27.001179  20.892721  13.341542\n",
      "  41.368156  76.27464  127.84033  151.06038  180.83553  234.05795\n",
      " 269.5996   276.5544   272.51114  249.05794  215.64568  174.96541\n",
      " 126.61858   78.892746  43.979527  28.17303   22.753366  16.79286\n",
      "  44.288837  84.426765 134.41443  153.4192   174.16182  215.64203\n",
      " 256.13904  275.22375  276.88196  256.7256   224.31337  188.71053 ]\n",
      "y_hat_test_RNN shape (48,)\n",
      "df shape (49,)\n",
      "Test Models\n",
      "Train LSTM\n",
      "windowForForecast (5,)\n",
      "series_type Hourly\n",
      "y_hat_test_RNN [ 2.3547466e+01  2.2605843e+01  2.1453136e+01  1.9949289e+01\n",
      "  1.8735388e+01  1.7832836e+01  1.6842072e+01  1.5892352e+01\n",
      "  1.5017724e+01  1.4165138e+01  1.3309797e+01  1.2465023e+01\n",
      "  1.1615330e+01  1.0758458e+01  9.9003716e+00  9.0393162e+00\n",
      "  8.1741667e+00  7.3078723e+00  6.4402475e+00  5.5683255e+00\n",
      "  4.6968999e+00  3.8293760e+00  2.9628358e+00  2.1113269e+00\n",
      "  1.3025441e+00  5.8764219e-01 -4.0256395e-03 -4.5836240e-01\n",
      " -7.8809351e-01 -1.0310397e+00 -1.2256547e+00 -1.3985646e+00\n",
      " -1.5661935e+00 -1.7374414e+00 -1.9176981e+00 -2.1111257e+00\n",
      " -2.3217442e+00 -2.5541067e+00 -2.8136053e+00 -3.1067383e+00\n",
      " -3.4413502e+00 -3.8268158e+00 -4.2741175e+00 -4.7953963e+00\n",
      " -5.4031549e+00 -6.1071653e+00 -6.9119220e+00 -7.8018336e+00]\n",
      "y_hat_test_RNN shape (48,)\n",
      "df shape (49,)\n",
      "Test Models\n",
      "Train LSTM\n",
      "windowForForecast (5,)\n",
      "series_type Hourly\n",
      "y_hat_test_RNN [-449.6407   -243.42917   -20.511673  -64.930595 -196.07066  -112.75803\n",
      "   45.666054  100.71529   141.99432   173.30685    99.79889   163.21075\n",
      "  190.4899    242.36496   239.72743   349.90546   378.78506   395.40228\n",
      "  315.32364   217.04883   217.68558   199.43521   125.59485   134.08185\n",
      "  287.82544   363.0031    326.7002    296.0384    247.70732   181.93867\n",
      "  130.19798   110.597626  143.94327   198.5434    161.52318   179.05772\n",
      "  283.04886   402.48334   430.396     399.9922    329.55087   257.3547\n",
      "  252.1848    206.39636   141.06068   127.9975    207.9807    298.3181  ]\n",
      "y_hat_test_RNN shape (48,)\n",
      "df shape (49,)\n",
      "Test Models\n",
      "Train LSTM\n",
      "windowForForecast (5,)\n",
      "series_type Hourly\n",
      "y_hat_test_RNN [-0.08909395 -0.06990044 -0.0518323  -0.03526412 -0.02467988 -0.01767664\n",
      " -0.01357252 -0.01209338 -0.01254106 -0.01421373 -0.01663366 -0.019367\n",
      " -0.02208106 -0.02455377 -0.02665226 -0.02831407 -0.02953415 -0.03034645\n",
      " -0.03080874 -0.03099044 -0.03096314 -0.03079378 -0.03054052 -0.03025053\n",
      " -0.02995947 -0.02969207 -0.02946341 -0.02928067 -0.02914498 -0.02905316\n",
      " -0.02899935 -0.02897631 -0.02897646 -0.02899264 -0.02901852 -0.02904894\n",
      " -0.02907994 -0.02910874 -0.02913361 -0.02915368 -0.02916875 -0.0291791\n",
      " -0.02918532 -0.02918818 -0.02918845 -0.02918694 -0.0291843  -0.02918111]\n",
      "y_hat_test_RNN shape (48,)\n",
      "df shape (49,)\n",
      "Test Models\n",
      "Train LSTM\n",
      "windowForForecast (5,)\n",
      "series_type Hourly\n",
      "y_hat_test_RNN [-133.75175   -32.20126    -5.346676   42.803867  -57.66268    21.353296\n",
      "   16.646063  -76.62651  -132.92874  -189.87787  -191.23274  -162.76456\n",
      "  -99.513275  -41.9045    -22.558815  -24.000784 -118.21039  -171.53029\n",
      "  -86.787056  -43.688957  -72.63927  -151.45413  -234.34985  -231.55432\n",
      " -157.19566   -43.616493    5.56465    62.16011   -17.00501    66.61298\n",
      "  103.5027    151.26039   126.11059   207.8118    203.90492   196.76263\n",
      "  163.01744   200.67844   180.76727   139.32332    96.701485  131.77661\n",
      "  110.11179    74.13995    79.993065   34.89536    39.31142   106.44987 ]\n",
      "y_hat_test_RNN shape (48,)\n",
      "df shape (49,)\n",
      "Test Models\n",
      "Train LSTM\n",
      "windowForForecast (5,)\n",
      "series_type Hourly\n",
      "y_hat_test_RNN [-377.0825   -317.8739   -321.74384  -357.45712  -370.15363  -353.6168\n",
      " -326.0996   -308.1751   -292.11566  -294.87625  -342.80814  -373.5757\n",
      " -372.73428  -337.28397  -317.4607   -317.5531   -322.61374  -343.9387\n",
      " -353.93616  -347.90582  -315.25812  -264.01538  -190.60632  -126.008995\n",
      "  -41.77937    70.48643   151.75389   239.66061   443.89612   499.0449\n",
      "  458.90408   438.08743   416.88977   383.95258   320.7187    232.60179\n",
      "  137.91068    29.789345   82.377945  234.81497   338.06967   313.25323\n",
      "  254.33867   212.66396   161.3768     91.18207   174.84395   306.75555 ]\n",
      "y_hat_test_RNN shape (48,)\n",
      "df shape (49,)\n",
      "Test Models\n",
      "Train LSTM\n",
      "windowForForecast (5,)\n",
      "series_type Hourly\n",
      "y_hat_test_RNN [-0.03546541  5.0652905   3.3545117   8.221542    2.281627    5.194614\n",
      " -1.2018582  -1.8109305  -5.900676   -4.5706124  -5.378103    4.658331\n",
      " -6.408432   -7.8103156  -3.758514    1.286522    6.644824    1.3064064\n",
      "  0.8927785  -3.2489533  -1.720647   -9.099063   -0.794767    4.346067\n",
      " -1.0769411   3.741933   -6.170849    7.8784156   3.0457006  -3.23426\n",
      " -1.3887763  -2.0886602  -5.7800736   3.9081156   3.994429    1.6929616\n",
      "  2.8798206  -2.6849723  -6.8422694  -7.8996606  -2.0350335  -4.8105893\n",
      " -3.4135435   0.02307394  1.261615   -2.995033   -0.3607304  -2.5287364 ]\n",
      "y_hat_test_RNN shape (48,)\n",
      "df shape (49,)\n",
      "Test Models\n",
      "Monthly\n",
      "Prepare Data\n",
      "Train LSTM\n",
      "windowForForecast (5,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/anaconda3/envs/jupyter/lib/python3.6/site-packages/ipykernel_launcher.py:88: FutureWarning: pd.rolling_mean is deprecated for Series and will be removed in a future version, replace with \n",
      "\tSeries.rolling(window=12,center=True).mean()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "series_type Monthly\n",
      "y_hat_test_RNN [244.70439  250.2755   250.37881  245.64665  224.14828  200.66696\n",
      " 166.68881  117.965225  92.912575  80.48097   75.61079   78.81976\n",
      "  72.97565   71.66034   69.2022    66.113     65.03961   61.294277]\n",
      "y_hat_test_RNN shape (18,)\n",
      "df shape (49,)\n",
      "Test Models\n",
      "Train LSTM\n",
      "windowForForecast (5,)\n",
      "series_type Monthly\n",
      "y_hat_test_RNN [-72.95651     2.9509263 -60.09717   -24.30063    94.765396  -47.053894\n",
      "  99.2244     17.192709   94.61676    94.449455   32.193596   94.93939\n",
      "  93.99012    96.13373    95.780975   79.91398    88.09287    90.94686  ]\n",
      "y_hat_test_RNN shape (18,)\n",
      "df shape (49,)\n",
      "Test Models\n",
      "Train LSTM\n",
      "windowForForecast (5,)\n",
      "series_type Monthly\n",
      "y_hat_test_RNN [-104.82531  -100.11396   -99.64307   -99.27423   -98.9735    -98.63377\n",
      "  -98.510315  -98.48679   -98.47265   -98.46409   -98.45943   -98.45714\n",
      "  -98.45634   -98.455986  -98.45579   -98.45569   -98.45566   -98.45564 ]\n",
      "y_hat_test_RNN shape (18,)\n",
      "df shape (49,)\n",
      "Test Models\n",
      "Train LSTM\n",
      "windowForForecast (5,)\n",
      "series_type Monthly\n",
      "y_hat_test_RNN [ 42.840126   16.902422  -25.710531  -65.158806  -27.830627   46.632397\n",
      "  67.46134    79.92646    78.45808    30.148546    9.0911045 -37.16075\n",
      " -73.38879    14.892531   57.253845   43.20585    80.51228    72.4823   ]\n",
      "y_hat_test_RNN shape (18,)\n",
      "df shape (49,)\n",
      "Test Models\n",
      "Train LSTM\n",
      "windowForForecast (5,)\n",
      "series_type Monthly\n",
      "y_hat_test_RNN [  20.635511   -31.005592    -4.4953947  -66.59611    -87.23128\n",
      "  -94.15236   -158.25552   -160.30658   -162.51932   -156.81854\n",
      " -148.3484    -143.59602   -146.5342    -154.26784   -157.50423\n",
      " -155.37032   -150.37584   -146.91823  ]\n",
      "y_hat_test_RNN shape (18,)\n",
      "df shape (49,)\n",
      "Test Models\n",
      "Train LSTM\n",
      "windowForForecast (5,)\n",
      "series_type Monthly\n",
      "y_hat_test_RNN [-33.670765  66.31902   67.96907   24.715107   7.283878  12.953725\n",
      "   9.748783 -40.119152 -70.40164  -65.5641   -68.112144 -64.519806\n",
      " -64.53902  -63.906364 -63.986473 -63.872265 -63.94265  -63.93527 ]\n",
      "y_hat_test_RNN shape (18,)\n",
      "df shape (49,)\n",
      "Test Models\n",
      "Train LSTM\n",
      "windowForForecast (5,)\n",
      "series_type Monthly\n",
      "y_hat_test_RNN [101.96821  100.921295 100.68037  100.510216 100.29357  100.334816\n",
      " 100.33095  100.33115  100.33101  100.33122  100.331184 100.33119\n",
      " 100.33119  100.33119  100.33119  100.33119  100.33119  100.33119 ]\n",
      "y_hat_test_RNN shape (18,)\n",
      "df shape (49,)\n",
      "Test Models\n",
      "Train LSTM\n",
      "windowForForecast (5,)\n",
      "series_type Monthly\n",
      "y_hat_test_RNN [30.572256 40.7648   48.014843 47.290936 46.53641  41.15593  41.467632\n",
      " 42.072937 42.140553 42.06357  41.50431  41.43742  41.463886 41.47301\n",
      " 41.461327 41.4005   41.382103 41.3787  ]\n",
      "y_hat_test_RNN shape (18,)\n",
      "df shape (49,)\n",
      "Test Models\n",
      "Train LSTM\n",
      "windowForForecast (5,)\n",
      "series_type Monthly\n",
      "y_hat_test_RNN [ -4.5713897  22.557817   53.51508    44.155724   28.046616   28.725897\n",
      "  29.84174    28.871714   28.614239   21.219822   15.694316   14.487561\n",
      "   7.684232    5.1927295   1.3579597  -4.6924467  -5.6039495 -13.585286 ]\n",
      "y_hat_test_RNN shape (18,)\n",
      "df shape (49,)\n",
      "Test Models\n",
      "Train LSTM\n",
      "windowForForecast (5,)\n",
      "series_type Monthly\n",
      "y_hat_test_RNN [50.53027   36.089977   8.252505   4.819857  32.191982  44.188732\n",
      " 51.566345  22.643278   5.640789  11.469816  32.040764  49.537098\n",
      " 50.960033  10.130888  -1.1741378 14.205923  35.39569   52.649303 ]\n",
      "y_hat_test_RNN shape (18,)\n",
      "df shape (49,)\n",
      "Test Models\n",
      "Train LSTM\n",
      "windowForForecast (5,)\n",
      "series_type Monthly\n",
      "y_hat_test_RNN [240.35286 241.51587 241.61397 241.58713 241.52542 241.12497 241.12329\n",
      " 241.1211  241.11841 241.11678 241.11661 241.11658 241.11653 241.11653\n",
      " 241.11653 241.11653 241.11653 241.11653]\n",
      "y_hat_test_RNN shape (18,)\n",
      "df shape (49,)\n",
      "Test Models\n",
      "Train LSTM\n",
      "windowForForecast (5,)\n",
      "series_type Monthly\n",
      "y_hat_test_RNN [-401.7442   -392.4335   -380.34586  -364.57953  -339.2037   -318.0848\n",
      " -293.77176  -265.34308  -231.34778  -187.99245  -143.47769  -110.11338\n",
      "  -88.36745   -51.203915  -86.65762   -86.66999   -64.82154   -82.97302 ]\n",
      "y_hat_test_RNN shape (18,)\n",
      "df shape (49,)\n",
      "Test Models\n",
      "Train LSTM\n",
      "windowForForecast (5,)\n",
      "series_type Monthly\n",
      "y_hat_test_RNN [ -62.9932     25.56642    68.95166    44.245003   47.27611    47.8756\n",
      "  -67.29159  -104.1356   -104.60108  -100.81219   -84.27933    16.001371\n",
      "   63.76411    52.36595    46.39605    47.567417  -65.7349   -104.313126]\n",
      "y_hat_test_RNN shape (18,)\n",
      "df shape (49,)\n",
      "Test Models\n",
      "Train LSTM\n",
      "windowForForecast (5,)\n",
      "series_type Monthly\n",
      "y_hat_test_RNN [ 65.87197     61.08069     50.243088    41.46921     27.81948\n",
      "  35.001133    23.155188    15.091477    13.404034     4.8825083\n",
      "   0.52135515  -2.9400654   -5.6508503  -12.246763   -12.351667\n",
      "  91.11099     76.10725     76.10477   ]\n",
      "y_hat_test_RNN shape (18,)\n",
      "df shape (49,)\n",
      "Test Models\n",
      "Train LSTM\n",
      "windowForForecast (5,)\n",
      "series_type Monthly\n",
      "y_hat_test_RNN [-38.190434 -34.776627 -18.181131  28.774761  40.253746  44.356636\n",
      "  51.660915  48.181698  17.853453  22.828423  14.27503   31.423248\n",
      "  19.094053  18.82132   13.654401 -44.684803 -33.015827 -38.537815]\n",
      "y_hat_test_RNN shape (18,)\n",
      "df shape (49,)\n",
      "Test Models\n",
      "Train LSTM\n",
      "windowForForecast (5,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/anaconda3/envs/jupyter/lib/python3.6/site-packages/ipykernel_launcher.py:92: FutureWarning: pd.rolling_mean is deprecated for Series and will be removed in a future version, replace with \n",
      "\tSeries.rolling(window=12,center=True).mean()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "series_type Monthly\n",
      "y_hat_test_RNN [-167.33057  -162.71555  -155.55203  -143.54248  -124.09134   -96.95714\n",
      "  -76.755646  -83.38384  -103.95899  -140.39642  -159.54962  -164.9352\n",
      " -164.13127  -156.57329  -146.5036   -130.39026  -107.19244   -84.99782 ]\n",
      "y_hat_test_RNN shape (18,)\n",
      "df shape (49,)\n",
      "Test Models\n",
      "Train LSTM\n",
      "windowForForecast (5,)\n",
      "series_type Monthly\n",
      "y_hat_test_RNN [59.84594  57.842693 57.328453 56.60876  55.735016 55.949615 55.853107\n",
      " 55.774773 55.776165 55.785538 55.771076 55.771378 55.7729   55.771812\n",
      " 55.77131  55.771675 55.771576 55.771492]\n",
      "y_hat_test_RNN shape (18,)\n",
      "df shape (49,)\n",
      "Test Models\n",
      "Train LSTM\n",
      "windowForForecast (5,)\n",
      "series_type Monthly\n",
      "y_hat_test_RNN [98.21087  97.05809  95.58485  93.87512  93.26293  92.98489  92.64319\n",
      " 92.485916 92.40661  92.3328   92.29043  92.26773  92.24991  92.23869\n",
      " 92.23225  92.22766  92.22467  92.222855]\n",
      "y_hat_test_RNN shape (18,)\n",
      "df shape (49,)\n",
      "Test Models\n",
      "Train LSTM\n",
      "windowForForecast (5,)\n",
      "series_type Monthly\n",
      "y_hat_test_RNN [-234.48563 -233.92432 -233.93668 -233.93596 -233.86296 -233.7833\n",
      " -233.78253 -233.78249 -233.78241 -233.78218 -233.78207 -233.78207\n",
      " -233.78207 -233.78207 -233.78207 -233.78207 -233.78207 -233.78207]\n",
      "y_hat_test_RNN shape (18,)\n",
      "df shape (49,)\n",
      "Test Models\n",
      "Train LSTM\n",
      "windowForForecast (5,)\n",
      "series_type Monthly\n",
      "y_hat_test_RNN [-154.51292 -154.24352 -154.29565 -154.29738 -154.29239 -154.29118\n",
      " -154.29109 -154.29112 -154.29112 -154.29112 -154.29112 -154.29112\n",
      " -154.29112 -154.29112 -154.29112 -154.29112 -154.29112 -154.29112]\n",
      "y_hat_test_RNN shape (18,)\n",
      "df shape (49,)\n",
      "Test Models\n",
      "Quaterly\n",
      "Prepare Data\n",
      "Train LSTM\n",
      "windowForForecast (5,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/anaconda3/envs/jupyter/lib/python3.6/site-packages/ipykernel_launcher.py:92: FutureWarning: pd.rolling_mean is deprecated for Series and will be removed in a future version, replace with \n",
      "\tSeries.rolling(window=4,center=True).mean()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "series_type Quaterly\n",
      "y_hat_test_RNN [-48.785614  -19.146646   -8.3629265   5.5011053  21.35555    28.103687\n",
      "  27.977356   25.137577 ]\n",
      "y_hat_test_RNN shape (8,)\n",
      "df shape (49,)\n",
      "Test Models\n",
      "Train LSTM\n",
      "windowForForecast (5,)\n",
      "series_type Quaterly\n",
      "y_hat_test_RNN [ 21.05193   51.30295   29.3692   -10.278424  23.068336  17.35085\n",
      "  39.08306   50.48009 ]\n",
      "y_hat_test_RNN shape (8,)\n",
      "df shape (49,)\n",
      "Test Models\n",
      "Train LSTM\n",
      "windowForForecast (5,)\n",
      "series_type Quaterly\n",
      "y_hat_test_RNN [-35.979126 -37.0401   -38.68551  -40.327637 -40.047764 -40.27954\n",
      " -40.29599  -40.359592]\n",
      "y_hat_test_RNN shape (8,)\n",
      "df shape (49,)\n",
      "Test Models\n",
      "Train LSTM\n",
      "windowForForecast (5,)\n",
      "series_type Quaterly\n",
      "y_hat_test_RNN [ 63.343075   25.792728  -11.2961645 -72.99383   -93.53572   -88.93789\n",
      "  -8.875158   29.17389  ]\n",
      "y_hat_test_RNN shape (8,)\n",
      "df shape (49,)\n",
      "Test Models\n",
      "Train LSTM\n",
      "windowForForecast (5,)\n",
      "series_type Quaterly\n",
      "y_hat_test_RNN [-53.551285 -49.927235 -45.729893 -44.19748  -45.461544 -41.441246\n",
      " -41.316418 -40.51721 ]\n",
      "y_hat_test_RNN shape (8,)\n",
      "df shape (49,)\n",
      "Test Models\n",
      "Train LSTM\n",
      "windowForForecast (5,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/anaconda3/envs/jupyter/lib/python3.6/site-packages/ipykernel_launcher.py:88: FutureWarning: pd.rolling_mean is deprecated for Series and will be removed in a future version, replace with \n",
      "\tSeries.rolling(window=4,center=True).mean()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "series_type Quaterly\n",
      "y_hat_test_RNN [-62.01335   49.07371   19.4212   -92.26602   19.606253  62.853226\n",
      " -71.60842  -89.88366 ]\n",
      "y_hat_test_RNN shape (8,)\n",
      "df shape (49,)\n",
      "Test Models\n",
      "Train LSTM\n",
      "windowForForecast (5,)\n",
      "series_type Quaterly\n",
      "y_hat_test_RNN [68.23239  68.38317  68.360214 68.32397  68.230484 14.820483  4.433389\n",
      "  5.853091]\n",
      "y_hat_test_RNN shape (8,)\n",
      "df shape (49,)\n",
      "Test Models\n",
      "Train LSTM\n",
      "windowForForecast (5,)\n",
      "series_type Quaterly\n",
      "y_hat_test_RNN [-62.405666 -54.128277 -54.849224 -53.795666 -45.15439  -30.360214\n",
      " -20.228403 -12.976864]\n",
      "y_hat_test_RNN shape (8,)\n",
      "df shape (49,)\n",
      "Test Models\n",
      "Train LSTM\n",
      "windowForForecast (5,)\n",
      "series_type Quaterly\n",
      "y_hat_test_RNN [269.064    249.3041   211.26297  177.7451   137.21263  105.754486\n",
      "  81.766106  55.351875]\n",
      "y_hat_test_RNN shape (8,)\n",
      "df shape (49,)\n",
      "Test Models\n",
      "Train LSTM\n",
      "windowForForecast (5,)\n",
      "series_type Quaterly\n",
      "y_hat_test_RNN [-33.9016   -32.127026 -30.957378 -30.484133 -30.262325 -29.956015\n",
      " -29.82815  -29.754524]\n",
      "y_hat_test_RNN shape (8,)\n",
      "df shape (49,)\n",
      "Test Models\n",
      "Train LSTM\n",
      "windowForForecast (5,)\n",
      "series_type Quaterly\n",
      "y_hat_test_RNN [ -37.79365    -98.25601   -185.0806    -180.11646     25.4281\n",
      "  -75.88192      0.6804199 -178.37471  ]\n",
      "y_hat_test_RNN shape (8,)\n",
      "df shape (49,)\n",
      "Test Models\n",
      "Train LSTM\n",
      "windowForForecast (5,)\n",
      "series_type Quaterly\n",
      "y_hat_test_RNN [  0.15375777  63.10232    -99.396225   -88.93536    -86.06073\n",
      "  -1.4189519  -74.60358    -53.064518  ]\n",
      "y_hat_test_RNN shape (8,)\n",
      "df shape (49,)\n",
      "Test Models\n",
      "Train LSTM\n",
      "windowForForecast (5,)\n",
      "series_type Quaterly\n",
      "y_hat_test_RNN [108.602295  91.6294    75.20711   61.509823  43.792107  13.915535\n",
      " -18.517496 -71.56104 ]\n",
      "y_hat_test_RNN shape (8,)\n",
      "df shape (49,)\n",
      "Test Models\n",
      "Train LSTM\n",
      "windowForForecast (5,)\n",
      "series_type Quaterly\n",
      "y_hat_test_RNN [-53.59796   -38.920067    3.4280827  69.23876    71.32329    70.25327\n",
      "  69.54335    34.21964  ]\n",
      "y_hat_test_RNN shape (8,)\n",
      "df shape (49,)\n",
      "Test Models\n",
      "Train LSTM\n",
      "windowForForecast (5,)\n",
      "series_type Quaterly\n",
      "y_hat_test_RNN [-46.706978    -0.45503044 -36.7748     -51.959145   -80.029434\n",
      " -68.81318      4.7603416  -16.6172    ]\n",
      "y_hat_test_RNN shape (8,)\n",
      "df shape (49,)\n",
      "Test Models\n",
      "Train LSTM\n",
      "windowForForecast (5,)\n",
      "series_type Quaterly\n",
      "y_hat_test_RNN [ 17.965569 -15.530793 -24.960407 -44.177635 -34.03299   13.342454\n",
      "  48.897556  62.446377]\n",
      "y_hat_test_RNN shape (8,)\n",
      "df shape (49,)\n",
      "Test Models\n",
      "Train LSTM\n",
      "windowForForecast (5,)\n",
      "series_type Quaterly\n",
      "y_hat_test_RNN [-40.21552   -50.689823    0.2993069 -21.676271   -2.5644305 -11.280805\n",
      " -52.832497  -27.78271  ]\n",
      "y_hat_test_RNN shape (8,)\n",
      "df shape (49,)\n",
      "Test Models\n",
      "Train LSTM\n",
      "windowForForecast (5,)\n",
      "series_type Quaterly\n",
      "y_hat_test_RNN [ 31.521776   10.281779   -4.2746754 -36.25408   -31.223055  -25.696564\n",
      "   5.906165   48.011883 ]\n",
      "y_hat_test_RNN shape (8,)\n",
      "df shape (49,)\n",
      "Test Models\n",
      "Train LSTM\n",
      "windowForForecast (5,)\n",
      "series_type Quaterly\n",
      "y_hat_test_RNN [ 40.81977  -15.895536 -65.17937  -72.48953  -73.93711  -71.84442\n",
      " -11.520594  28.231333]\n",
      "y_hat_test_RNN shape (8,)\n",
      "df shape (49,)\n",
      "Test Models\n",
      "Train LSTM\n",
      "windowForForecast (5,)\n",
      "series_type Quaterly\n",
      "y_hat_test_RNN [-79.416336 -67.24967  -83.07285  126.54642  -48.971684   6.901234\n",
      " 138.10817  -65.94377 ]\n",
      "y_hat_test_RNN shape (8,)\n",
      "df shape (49,)\n",
      "Test Models\n",
      "Yearly\n",
      "Prepare Data\n",
      "Train LSTM\n",
      "windowForForecast (5,)\n",
      "series_type Yearly\n",
      "y_hat_test_RNN [21.334494]\n",
      "y_hat_test_RNN shape (1,)\n",
      "df shape (49,)\n",
      "Test Models\n",
      "Train LSTM\n",
      "windowForForecast (5,)\n",
      "series_type Yearly\n",
      "y_hat_test_RNN [29.290262]\n",
      "y_hat_test_RNN shape (1,)\n",
      "df shape (49,)\n",
      "Test Models\n",
      "Train LSTM\n",
      "windowForForecast (5,)\n",
      "series_type Yearly\n",
      "y_hat_test_RNN [-41.240723]\n",
      "y_hat_test_RNN shape (1,)\n",
      "df shape (49,)\n",
      "Test Models\n",
      "Train LSTM\n",
      "windowForForecast (5,)\n",
      "series_type Yearly\n",
      "y_hat_test_RNN [-3.1056483]\n",
      "y_hat_test_RNN shape (1,)\n",
      "df shape (49,)\n",
      "Test Models\n",
      "Train LSTM\n",
      "windowForForecast (5,)\n",
      "series_type Yearly\n",
      "y_hat_test_RNN [2.468646]\n",
      "y_hat_test_RNN shape (1,)\n",
      "df shape (49,)\n",
      "Test Models\n",
      "Train LSTM\n",
      "windowForForecast (5,)\n",
      "series_type Yearly\n",
      "y_hat_test_RNN [47.934216]\n",
      "y_hat_test_RNN shape (1,)\n",
      "df shape (49,)\n",
      "Test Models\n",
      "Train LSTM\n",
      "windowForForecast (5,)\n",
      "series_type Yearly\n",
      "y_hat_test_RNN [8.50163]\n",
      "y_hat_test_RNN shape (1,)\n",
      "df shape (49,)\n",
      "Test Models\n",
      "Train LSTM\n",
      "windowForForecast (5,)\n",
      "series_type Yearly\n",
      "y_hat_test_RNN [20.9312]\n",
      "y_hat_test_RNN shape (1,)\n",
      "df shape (49,)\n",
      "Test Models\n",
      "Train LSTM\n",
      "windowForForecast (5,)\n",
      "series_type Yearly\n",
      "y_hat_test_RNN [31.836794]\n",
      "y_hat_test_RNN shape (1,)\n",
      "df shape (49,)\n",
      "Test Models\n",
      "Train LSTM\n",
      "windowForForecast (5,)\n",
      "series_type Yearly\n",
      "y_hat_test_RNN [18.53809]\n",
      "y_hat_test_RNN shape (1,)\n",
      "df shape (49,)\n",
      "Test Models\n",
      "Train LSTM\n",
      "windowForForecast (5,)\n",
      "series_type Yearly\n",
      "y_hat_test_RNN [25.039375]\n",
      "y_hat_test_RNN shape (1,)\n",
      "df shape (49,)\n",
      "Test Models\n",
      "Train LSTM\n",
      "windowForForecast (5,)\n",
      "series_type Yearly\n",
      "y_hat_test_RNN [-35.846863]\n",
      "y_hat_test_RNN shape (1,)\n",
      "df shape (49,)\n",
      "Test Models\n",
      "Train LSTM\n",
      "windowForForecast (5,)\n",
      "series_type Yearly\n",
      "y_hat_test_RNN [33.13807]\n",
      "y_hat_test_RNN shape (1,)\n",
      "df shape (49,)\n",
      "Test Models\n",
      "Train LSTM\n",
      "windowForForecast (5,)\n",
      "series_type Yearly\n",
      "y_hat_test_RNN [-4.4730387]\n",
      "y_hat_test_RNN shape (1,)\n",
      "df shape (49,)\n",
      "Test Models\n",
      "Train LSTM\n",
      "windowForForecast (5,)\n",
      "series_type Yearly\n",
      "y_hat_test_RNN [23.467117]\n",
      "y_hat_test_RNN shape (1,)\n",
      "df shape (49,)\n",
      "Test Models\n",
      "Train LSTM\n",
      "windowForForecast (5,)\n",
      "series_type Yearly\n",
      "y_hat_test_RNN [-11.059236]\n",
      "y_hat_test_RNN shape (1,)\n",
      "df shape (49,)\n",
      "Test Models\n",
      "Train LSTM\n",
      "windowForForecast (5,)\n",
      "series_type Yearly\n",
      "y_hat_test_RNN [24.589567]\n",
      "y_hat_test_RNN shape (1,)\n",
      "df shape (49,)\n",
      "Test Models\n",
      "Train LSTM\n",
      "windowForForecast (5,)\n",
      "series_type Yearly\n",
      "y_hat_test_RNN [-41.519817]\n",
      "y_hat_test_RNN shape (1,)\n",
      "df shape (49,)\n",
      "Test Models\n",
      "Train LSTM\n",
      "windowForForecast (5,)\n",
      "series_type Yearly\n",
      "y_hat_test_RNN [-7.9377475]\n",
      "y_hat_test_RNN shape (1,)\n",
      "df shape (49,)\n",
      "Test Models\n",
      "Train LSTM\n",
      "windowForForecast (5,)\n",
      "series_type Yearly\n",
      "y_hat_test_RNN [25.620546]\n",
      "y_hat_test_RNN shape (1,)\n",
      "df shape (49,)\n",
      "Test Models\n"
     ]
    }
   ],
   "source": [
    "p=['Daily','Weekly','Hourly','Monthly','Quaterly','Yearly']\n",
    "fcs=[14,13,48,18,8,1]\n",
    "frqs=[1,1,24,12,4,1]\n",
    "size=20\n",
    "all_forecasts=np.zeros((100000,49))\n",
    "all_forecasts.fill(np.nan)\n",
    "all_forecasts\n",
    "columns=['id']\n",
    "for i in range(1,49):\n",
    "    columns.append('F'+str(i))\n",
    "columns\n",
    "df=pd.DataFrame(all_forecasts,columns=columns)\n",
    "df.fillna\n",
    "forecasts_path='../results/forecasts-'+str(size)+'.csv'\n",
    "#df.to_csv(forecasts_path, index=False)\n",
    "\n",
    "test1=[]\n",
    "test2=[]\n",
    "for x in range(0,len(p)):\n",
    "    print(p[x])\n",
    "    path=\"\".join([\"../data/csv_\",str(size),\"_sample/\", str(p[x]),'-train-',str(size),'-sample.csv'])\n",
    "    \n",
    "    main(path,fcs[x],frqs[x],df,p[x],forecasts_path)\n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('smape',test1,'mase',test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'flatten'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-62-fb2dab076bc7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m  \u001b[0;34m[\u001b[0m\u001b[0;36m916.1903\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m  [916.1859 ]]\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'flatten'"
     ]
    }
   ],
   "source": [
    "df=[[927.9543 ],\n",
    " [919.9753 ],\n",
    " [916.0806 ],\n",
    " [914.976  ],\n",
    " [915.10547],\n",
    " [915.569  ],\n",
    " [915.94727],\n",
    " [916.1538 ],\n",
    " [916.2281 ],\n",
    " [916.23413],\n",
    " [916.2175 ],\n",
    " [916.20074],\n",
    " [916.1903 ],\n",
    " [916.1859 ]]\n",
    "df.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   A  B  C\n",
       "0  0  1  2\n",
       "1  0  0  0"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame([[0,0,0],[0,0,0]],columns=['A','B','C'])\n",
    "a=[1,2]\n",
    "df.iloc[0,1]='dadad'[0]+str(1)\n",
    "df.iloc[0,1:len(a)+1]=a\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "v1 = array(1, dim=c(8,length(p)*size))\n",
    "v2 = array(1, dim=c(8,length(p)*size))\n",
    "    glimpse(v1)\n",
    "\n",
    "for (x in 1:length(p)){   \n",
    "    v1[,((x-1)*size+1):(x*size)]=test1[[x]]\n",
    "    v2[,((x-1)*size+1):(x*size)]=test2[[x]]\n",
    "}\n",
    "glimpse(v1)\n",
    "glimpse(v2)\n",
    "\n",
    "Total_mase=v2\n",
    "Total_smape=v1\n",
    "result=array(NA,dim = c(length(Names_benchmarks), 4))\n",
    "print(\"########### sMAPE ###############\")\n",
    "for (i in range(1,len(Names_benchmarks)){\n",
    "  smape=round(np.mean(Total_smape[i,]), 3)\n",
    "  mase=round(np.mean(Total_mase[i,]), 3)\n",
    "  owa=round(((np.mean(Total_mase[i,])/mean(Total_mase[3,]))+(mean(Total_smape[i,])/mean(Total_smape[3,])))/2, 3)\n",
    "  \n",
    "  result[i,1]=Names_benchmarks[i]\n",
    "  result[i,2]=smape\n",
    "  result[i,3]=mase\n",
    "  result[i,4]=owa  \n",
    "  \n",
    "  print(paste(Names_benchmarks[i], smape, mase, owa))\n",
    "}\n",
    "write.csv(result, file = paste(\"../results/R-Benchmark-\",size,'-sample.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_all():\n",
    "    \n",
    "    print(\"### Load of Dataset  ###\")\n",
    "    #df_yearly = pd.read_csv(\"../M4-methods/csv_20_sample/Yearly-train-20-sample.csv\", skiprows=0, index_col =0)\n",
    "    #df_quaterly = pd.read_csv(\"../M4-methods/csv_20_sample/Quaterly-train-20-sample.csv\", skiprows=0, index_col =0)\n",
    "    df_monthly = pd.read_csv(\"../M4-methods/csv_20_sample/Monthly-train-20-sample.csv\", skiprows=0, index_col =0)\n",
    "    df_weekly = pd.read_csv(\"../M4-methods/csv_20_sample/Weekly-train-20-sample.csv\", skiprows=0, index_col =0)\n",
    "    df_daily = pd.read_csv(\"../M4-methods/csv_20_sample/Daily-train-20-sample.csv\", skiprows=0, index_col =0)\n",
    "    df_hourly = pd.read_csv(\"../M4-methods/csv_20_sample/Hourly-train-20-sample.csv\", skiprows=0, index_col =0)\n",
    " \n",
    "    \n",
    "    D=[]\n",
    "   # D.append(df_yearly)\n",
    "   # D.append(df_quaterly)\n",
    "    D.append(df_monthly)\n",
    "    D.append(df_weekly)\n",
    "    D.append(df_daily)\n",
    "    D.append(df_hourly)\n",
    "    \n",
    "    columnsname= [\"Data_Type\",\"sMapeLSTM\",\"Mase LSTM\"]\n",
    "    ds = pd.DataFrame(columns=columnsname )\n",
    "    ds.to_csv('outpoutM4.csv')\n",
    "    print(ds.shape)\n",
    "    \n",
    "    for i in range (len(D)):\n",
    "        \n",
    "        if i==0:\n",
    "            print( \"*** Beginn of Monthly dataset ***\")\n",
    "            a,b = main(df_monthly,18,12,i)\n",
    "            p= [\"Monthly_data\",a,b]\n",
    "            ds.iloc[:,i]= p\n",
    "            ds=ds.round(4)\n",
    "            ds.to_csv('outputM4LSTM.csv', mode='a', header=False)\n",
    "        if i==1:\n",
    "            print( \"*** Beginn of Weekly dataset ***\")\n",
    "            a,b = main(df_weekly,13,1,i)\n",
    "            p= [\"Weekly_data\",a,b]\n",
    "            ds.iloc[:,i]= p\n",
    "            ds=ds.round(4)\n",
    "            ds.to_csv('outputM4LSTM.csv', mode='a', header=False)\n",
    "        if i==2:\n",
    "            print( \"*** Beginn of Daily dataset ***\")\n",
    "            a,b= main(df_daily,14,1,i)\n",
    "            p= [\"Daily_data\",a,b]\n",
    "            ds.iloc[:,i]= p\n",
    "            ds=ds.round(4)\n",
    "            ds.to_csv('outputM4LSTM.csv', mode='a', header=False)\n",
    "        if i==3:\n",
    "            print( \"*** Beginn of Hourly dataset ***\")\n",
    "            a,b = main(df_hourly,48,24,i)\n",
    "            p= [\"Hourly_data\",a,b]\n",
    "            ds.iloc[:,i]= p\n",
    "            ds=ds.round(4)\n",
    "            ds.to_csv('outputM4LSTM.csv', mode='a', header=False)\n",
    "    print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_forecasts=np.zeros((100000,49))\n",
    "all_forecasts.fill(np.nan)\n",
    "all_forecasts\n",
    "columns=['id']\n",
    "for i in range(1,49):\n",
    "    columns.append('F'+str(i))\n",
    "columns\n",
    "df=pd.DataFrame(all_forecasts,columns=columns)\n",
    "df.fillna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if i==0:\n",
    "            print( \"*** Beginn of yearly dataset ***\")\n",
    "            a,b = main(df_yearly,6,1,i)\n",
    "            p= [\"Yearly_data\",a,b]\n",
    "            ds.iloc[:,i]= p\n",
    "            ds=ds.round(4)\n",
    "            ds.to_csv('outputM4LSTM.csv', mode='a', header=False)\n",
    "        if i==1:\n",
    "            print( \"*** Beginn of Quarterly dataset ***\")\n",
    "            a,b = main(df_quaterly,8,4,i)\n",
    "            p= [\"Quarterly_data\",a,b]\n",
    "            ds.iloc[:,i]= p\n",
    "            ds=ds.round(4)\n",
    "            ds.to_csv('outputM4LSTM.csv', mode='a', header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "def main(data_path,fh,freq,df,series_type,forecasts_path):\n",
    "    print('Prepare Data')\n",
    "    data_all=pd.read_csv(data_path, skiprows=0, index_col =0)\n",
    "    in_size = 5    # number of points used as input for each forecast\n",
    "\n",
    "    err_RNN_sMAPE = []\n",
    "    err_RNN_MASE = []\n",
    "    \n",
    "\n",
    "    \n",
    "    counter = 0\n",
    "    # ===== Main loop which goes through all timeseries =====\n",
    "    for j in range(len(data_all)):\n",
    "        start = time.time()\n",
    "        \n",
    "        \n",
    "        ts = data_all.iloc[j, :]\n",
    "        ts = remov_nan(ts)\n",
    "\n",
    "        # remove seasonality\n",
    "        seasonality_in = deseasonalize(ts, freq)\n",
    "\n",
    "        for i in range(0, len(ts)):\n",
    "            ts[i] = ts[i] * 100 / seasonality_in[i % freq]\n",
    "\n",
    "        # detrending\n",
    "        a, b = detrend(ts)\n",
    "\n",
    "        for i in range(0, len(ts)):\n",
    "            ts[i] = ts[i] - ((a * i) + b)\n",
    "\n",
    "        x_train, y_train = windows_for_forecasts(ts, in_size, fh)\n",
    "        \n",
    "        \n",
    "       \n",
    "        # RNN benchmark - Produce forecasts\n",
    "        print('Train LSTM')\n",
    "        #y_hat_test_RNN = np.reshape(rnn_bench(x_train, y_train, x_test, fh, in_size), (-1))\n",
    "        windowForForecast=ts[len(ts)-in_size:]\n",
    "        print(windowForForecast,windowForForecast.shape)\n",
    "        lstm=LSTM_NN(x_train, y_train, windowForForecast, fh, in_size)\n",
    "        df.loc[j,0]=series_type[0]+str(j)\n",
    "        df.loc[j,1:len(forecast)+1]=forecast\n",
    "        df.to_csv(forecasts_path,mode='a', index=False)\n",
    "        y_hat_test_RNN = np.reshape(lstm, (-1))\n",
    "        print('Test Models')\n",
    "     \n",
    "\n",
    "        # add trend\n",
    "        for i in range(0, len(ts)):\n",
    "            ts[i] = ts[i] + ((a * i) + b)\n",
    "\n",
    "        for i in range(0, fh):\n",
    "            #y_hat_test_MLP[i] = y_hat_test_MLP[i] + ((a * (len(ts) + i + 1)) + b)\n",
    "            y_hat_test_RNN[i] = y_hat_test_RNN[i] + ((a * (len(ts) + i + 1)) + b)\n",
    "\n",
    "        # add seasonality\n",
    "        for i in range(0, len(ts)):\n",
    "            ts[i] = ts[i] * seasonality_in[i % freq] / 100\n",
    "\n",
    "        for i in range(len(ts), len(ts) + fh):\n",
    "            y_hat_test_RNN[i - len(ts)] = y_hat_test_RNN[i - len(ts)] * seasonality_in[i % freq] / 100\n",
    "\n",
    "        # check if negative or extreme\n",
    "        for i in range(len(y_hat_test_RNN)):\n",
    "       \n",
    "            if y_hat_test_RNN[i] < 0:\n",
    "                y_hat_test_RNN[i] = 0\n",
    "                \n",
    "            \n",
    "            if y_hat_test_RNN[i] > (1000 * max(ts)):\n",
    "                y_hat_test_RNN[i] = max(ts)\n",
    "\n",
    "        x_train, y_train, x_test, y_test = split_into_train_test(ts, in_size, fh)\n",
    "\n",
    "        # Calculate errors\n",
    "       # err_MLP_sMAPE.append(smape(y_test, y_hat_test_MLP))\n",
    "        err_RNN_sMAPE.append(smape(y_test, y_hat_test_RNN))\n",
    "      #  err_MLP_MASE.append(mase(ts[:-fh], y_test, y_hat_test_MLP, freq))\n",
    "        err_RNN_MASE.append(mase(ts[:-fh], y_test, y_hat_test_RNN, freq))\n",
    "\n",
    "        # memory handling\n",
    "        ker.clear_session()\n",
    "        tf.reset_default_graph()\n",
    "        gc.collect()\n",
    "\n",
    "        counter = counter + 1\n",
    "        #**********************************************************************\n",
    "        print(\"-------------TS ID: \", counter, \"-------------\")\n",
    "        print(\" sMAPE_RNN:\",err_RNN_sMAPE[-1],\" MASE_RNN:\",err_RNN_MASE[-1])\n",
    "        print(\"Time:\",time.time()-start)\n",
    "        #break\n",
    "        \n",
    "        #********************************************************************    \n",
    "    print(\"\\n\\n---------FINAL RESULTS---------\")\n",
    "    print(\"=============sMAPE=============\\n\")\n",
    "    print(\"#### RNN ####\\n\", np.mean(err_RNN_sMAPE), \"\\n\")\n",
    "    print(\"==============MASE=============\")\n",
    "    print(\"#### RNN ####\\n\", np.mean(err_RNN_MASE), \"\\n\")\n",
    "    return np.mean(err_RNN_sMAPE),np.mean(err_RNN_MASE)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyter",
   "language": "python",
   "name": "jupyter"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
