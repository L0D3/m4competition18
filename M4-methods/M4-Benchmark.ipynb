{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import seed\n",
    "seed(42)\n",
    "from tensorflow import set_random_seed\n",
    "set_random_seed(42)\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, SimpleRNN\n",
    "from keras.optimizers import rmsprop\n",
    "from keras import backend as ker\n",
    "from math import sqrt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import gc\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def remov_nan (dataset):\n",
    "    '''\n",
    "    to remove all NaN Values in a \n",
    "    Time Serie Dataframe\n",
    "    '''\n",
    "    n = dataset.isnull().sum() \n",
    "    data = dataset[0:(len(dataset)-n)]\n",
    "    return data\n",
    "\n",
    "\n",
    "def detrend(insample_data):\n",
    "    \"\"\"\n",
    "    Calculates a & b parameters of LRL\n",
    "\n",
    "    :param insample_data:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    x = np.arange(len(insample_data))\n",
    "    a, b = np.polyfit(x, insample_data, 1)\n",
    "    return a, b\n",
    "\n",
    "\n",
    "def deseasonalize(original_ts, ppy):\n",
    "    \"\"\"\n",
    "    Calculates and returns seasonal indices\n",
    "\n",
    "    :param original_ts: original data\n",
    "    :param ppy: periods per year\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    # === get in-sample data\n",
    "    original_ts = original_ts[:-out_of_sample]\n",
    "    \"\"\"\n",
    "    if seasonality_test(original_ts, ppy):\n",
    "        # print(\"seasonal\")\n",
    "        # ==== get moving averages\n",
    "        ma_ts = moving_averages(original_ts, ppy)\n",
    "\n",
    "        # ==== get seasonality indices\n",
    "        le_ts = original_ts * 100 / ma_ts\n",
    "        le_ts = np.hstack((le_ts, np.full((ppy - (len(le_ts) % ppy)), np.nan)))\n",
    "        le_ts = np.reshape(le_ts, (-1, ppy))\n",
    "        si = np.nanmean(le_ts, 0)\n",
    "        norm = np.sum(si) / (ppy * 100)\n",
    "        si = si / norm\n",
    "    else:\n",
    "        # print(\"NOT seasonal\")\n",
    "        si = np.full(ppy, 100)\n",
    "\n",
    "    return si\n",
    "\n",
    "\n",
    "def moving_averages(ts_init, window):\n",
    "    \"\"\"\n",
    "    Calculates the moving averages for a given TS\n",
    "\n",
    "    :param ts_init: the original time series\n",
    "    :param window: window length\n",
    "    :return: moving averages ts\n",
    "    \"\"\"\n",
    "    if len(ts_init) % 2 == 0:\n",
    "        ts_ma = pd.rolling_mean(ts_init, window, center=True)\n",
    "        ts_ma = pd.rolling_mean(ts_ma, 2, center=True)\n",
    "        ts_ma = np.roll(ts_ma, -1)\n",
    "    else:\n",
    "        ts_ma = pd.rolling_mean(ts_init, window, center=True)\n",
    "\n",
    "    return ts_ma\n",
    "\n",
    "\n",
    "def seasonality_test(original_ts, ppy):\n",
    "    \"\"\"\n",
    "    Seasonality test\n",
    "\n",
    "    :param original_ts: time series\n",
    "    :param ppy: periods per year\n",
    "    :return: boolean value: whether the TS is seasonal\n",
    "    \"\"\"\n",
    "    s = acf(original_ts, 1)\n",
    "    for i in range(2, ppy):\n",
    "        s = s + (acf(original_ts, i) ** 2)\n",
    "\n",
    "    limit = 1.645 * (sqrt((1 + 2 * s) / len(original_ts)))\n",
    "\n",
    "    return (abs(acf(original_ts, ppy))) > limit\n",
    "\n",
    "\n",
    "def acf(data, k):\n",
    "    \"\"\"\n",
    "    Autocorrelation function\n",
    "\n",
    "    :param data: time series\n",
    "    :param k: lag\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    m = np.mean(data)\n",
    "    s1 = 0\n",
    "    for i in range(k, len(data)):\n",
    "        s1 = s1 + ((data[i] - m) * (data[i - k] - m))\n",
    "\n",
    "    s2 = 0\n",
    "    for i in range(0, len(data)):\n",
    "        s2 = s2 + ((data[i] - m) ** 2)\n",
    "\n",
    "    return float(s1 / s2)\n",
    "\n",
    "\n",
    "def split_into_train_test(data, in_num, fh):\n",
    "    \"\"\"\n",
    "    Splits the series into train and test sets. Each step takes multiple points as inputs\n",
    "\n",
    "    :param data: an individual TS\n",
    "    :param fh: number of out of sample points\n",
    "    :param in_num: number of input points for the forecast\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    train, test = data[:-fh], data[-(fh + in_num):]\n",
    "    x_train, y_train = train[:-1], np.roll(train, -in_num)[:-in_num]\n",
    "    x_test, y_test = train[-in_num:], np.roll(test, -in_num)[:-in_num]\n",
    "\n",
    "    # reshape input to be [samples, time steps, features] (N-NF samples, 1 time step, 1 feature)\n",
    "    x_train = np.reshape(x_train, (-1, 1))\n",
    "    x_test = np.reshape(x_test, (-1, 1))\n",
    "    temp_test = np.roll(x_test, -1)\n",
    "    temp_train = np.roll(x_train, -1)\n",
    "    for x in range(1, in_num):\n",
    "        x_train = np.concatenate((x_train[:-1], temp_train[:-1]), 1)\n",
    "        x_test = np.concatenate((x_test[:-1], temp_test[:-1]), 1)\n",
    "        temp_test = np.roll(temp_test, -1)[:-1]\n",
    "        temp_train = np.roll(temp_train, -1)[:-1]\n",
    "\n",
    "    return x_train, y_train, x_test, y_test\n",
    "\n",
    "\n",
    "def rnn_bench(x_train, y_train, x_test, fh, input_size):\n",
    "    \"\"\"\n",
    "    Forecasts using 6 SimpleRNN nodes in the hidden layer and a Dense output layer\n",
    "\n",
    "    :param x_train: train data\n",
    "    :param y_train: target values for training\n",
    "    :param x_test: test data\n",
    "    :param fh: forecasting horizon\n",
    "    :param input_size: number of points used as input\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    # reshape to match expected input\n",
    "    x_train = np.reshape(x_train, (-1, input_size, 1))\n",
    "    x_test = np.reshape(x_test, (-1, input_size, 1))\n",
    "\n",
    "    # create the model\n",
    "    model = Sequential([\n",
    "        SimpleRNN(6, input_shape=(input_size, 1), activation='linear',\n",
    "                  use_bias=False, kernel_initializer='glorot_uniform',\n",
    "                  recurrent_initializer='orthogonal', bias_initializer='zeros',\n",
    "                  dropout=0.0, recurrent_dropout=0.0),\n",
    "        Dense(1, use_bias=True, activation='linear')\n",
    "    ])\n",
    "    opt = rmsprop(lr=0.001)\n",
    "    model.compile(loss='mean_squared_error', optimizer=opt)\n",
    "\n",
    "    # fit the model to the training data\n",
    "    model.fit(x_train, y_train, epochs=100, batch_size=1, verbose=0)\n",
    "\n",
    "    # make predictions\n",
    "    y_hat_test = []\n",
    "    last_prediction = model.predict(x_test)[0]\n",
    "    for i in range(0, fh):\n",
    "        y_hat_test.append(last_prediction)\n",
    "        x_test[0] = np.roll(x_test[0], -1)\n",
    "        x_test[0, (len(x_test[0]) - 1)] = last_prediction\n",
    "        last_prediction = model.predict(x_test)[0]\n",
    "\n",
    "    return np.asarray(y_hat_test)\n",
    "\n",
    "\n",
    "def mlp_bench(x_train, y_train, x_test, fh):\n",
    "    \"\"\"\n",
    "    Forecasts using a simple MLP which 6 nodes in the hidden layer\n",
    "\n",
    "    :param x_train: train input data\n",
    "    :param y_train: target values for training\n",
    "    :param x_test: test data\n",
    "    :param fh: forecasting horizon\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    y_hat_test = []\n",
    "\n",
    "    model = MLPRegressor(hidden_layer_sizes=6, activation='identity', solver='adam',\n",
    "                         max_iter=100, learning_rate='adaptive', learning_rate_init=0.001,\n",
    "                         random_state=42)\n",
    "    model.fit(x_train, y_train)\n",
    "\n",
    "    last_prediction = model.predict(x_test)[0]\n",
    "    for i in range(0, fh):\n",
    "        y_hat_test.append(last_prediction)\n",
    "        x_test[0] = np.roll(x_test[0], -1)\n",
    "        x_test[0, (len(x_test[0]) - 1)] = last_prediction\n",
    "        last_prediction = model.predict(x_test)[0]\n",
    "\n",
    "    return np.asarray(y_hat_test)\n",
    "\n",
    "\n",
    "def smape(a, b):\n",
    "    \"\"\"\n",
    "    Calculates sMAPE\n",
    "\n",
    "    :param a: actual values\n",
    "    :param b: predicted values\n",
    "    :return: sMAPE\n",
    "    \"\"\"\n",
    "    a = np.reshape(a, (-1,))\n",
    "    b = np.reshape(b, (-1,))\n",
    "    return np.mean(2.0 * np.abs(a - b) / (np.abs(a) + np.abs(b))).item()\n",
    "\n",
    "\n",
    "def mase(insample, y_test, y_hat_test, freq):\n",
    "    \"\"\"\n",
    "    Calculates MAsE\n",
    "\n",
    "    :param insample: insample data\n",
    "    :param y_test: out of sample target values\n",
    "    :param y_hat_test: predicted values\n",
    "    :param freq: data frequency\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    y_hat_naive = []\n",
    "    for i in range(freq, len(insample)):\n",
    "        y_hat_naive.append(insample[(i - freq)])\n",
    "\n",
    "    masep = np.mean(abs(insample[freq:] - y_hat_naive))\n",
    "\n",
    "    return np.mean(abs(y_test - y_hat_test)) / masep\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(data_all,fh,freq,j):\n",
    "    #fh = 6         # forecasting horizon\n",
    "    #freq = 1       # data frequency\n",
    "    in_size = 3    # number of points used as input for each forecast\n",
    "\n",
    "    \n",
    "    err_MLP_sMAPE = []\n",
    "    err_MLP_MASE = []\n",
    "    err_RNN_sMAPE = []\n",
    "    err_RNN_MASE = []\n",
    "    \n",
    "    columnsname= [\"sMape MLP\",\"sMape RNN\",\"Mase MLP\",\"Mase RNN\"]\n",
    "    ds = pd.DataFrame(columns=columnsname )\n",
    "    \n",
    "    if j==0:\n",
    "        ds.to_csv('out_yearly.csv')\n",
    "    if j==1:\n",
    "        ds.to_csv('out_quarterly.csv')\n",
    "    if j==2:\n",
    "        ds.to_csv('out_monthly.csv')\n",
    "    if j==3:\n",
    "        ds.to_csv('out_weekly.csv')\n",
    "    if j==4:\n",
    "        ds.to_csv('out_yearly.csv')\n",
    "    if j==5:\n",
    "        ds.to_csv('out_yearly.csv')\n",
    "        \n",
    "\n",
    "    # ===== In this example we produce forecasts for 100 randomly generated timeseries =====\n",
    "    \n",
    "    \n",
    "    #df_yearly = pd.read_csv(\"../data/Yearly-train.csv\", skiprows=0, index_col =0)\n",
    "    #data_all = df_yearly.T\n",
    "    #data_all = np.array(np.random.random_integers(0, 100, (100, 20)), dtype=np.float32)\n",
    "    #for i in range(0, 100):\n",
    "        #for j in range(0, 20):\n",
    "            #data_all[i, j] = j * 10 + data_all[i, j]\n",
    "    \n",
    "    counter = 0\n",
    "    # ===== Main loop which goes through all timeseries =====\n",
    "    for j in range(len(data_all)):\n",
    "        ts = data_all.iloc[j, :]\n",
    "        ts = remov_nan(ts)\n",
    "\n",
    "        # remove seasonality\n",
    "        seasonality_in = deseasonalize(ts, freq)\n",
    "\n",
    "        for i in range(0, len(ts)):\n",
    "            ts[i] = ts[i] * 100 / seasonality_in[i % freq]\n",
    "\n",
    "        # detrending\n",
    "        a, b = detrend(ts)\n",
    "\n",
    "        for i in range(0, len(ts)):\n",
    "            ts[i] = ts[i] - ((a * i) + b)\n",
    "\n",
    "        x_train, y_train, x_test, y_test = split_into_train_test(ts, in_size, fh)\n",
    "\n",
    "        # RNN benchmark - Produce forecasts\n",
    "        y_hat_test_RNN = np.reshape(rnn_bench(x_train, y_train, x_test, fh, in_size), (-1))\n",
    "\n",
    "        # MLP benchmark - Produce forecasts\n",
    "        y_hat_test_MLP = mlp_bench(x_train, y_train, x_test, fh)\n",
    "        for i in range(0, 29):\n",
    "            y_hat_test_MLP = np.vstack((y_hat_test_MLP, mlp_bench(x_train, y_train, x_test, fh)))\n",
    "        y_hat_test_MLP = np.median(y_hat_test_MLP, axis=0)\n",
    "\n",
    "        # add trend\n",
    "        for i in range(0, len(ts)):\n",
    "            ts[i] = ts[i] + ((a * i) + b)\n",
    "\n",
    "        for i in range(0, fh):\n",
    "            y_hat_test_MLP[i] = y_hat_test_MLP[i] + ((a * (len(ts) + i + 1)) + b)\n",
    "            y_hat_test_RNN[i] = y_hat_test_RNN[i] + ((a * (len(ts) + i + 1)) + b)\n",
    "\n",
    "        # add seasonality\n",
    "        for i in range(0, len(ts)):\n",
    "            ts[i] = ts[i] * seasonality_in[i % freq] / 100\n",
    "\n",
    "        for i in range(len(ts), len(ts) + fh):\n",
    "            y_hat_test_MLP[i - len(ts)] = y_hat_test_MLP[i - len(ts)] * seasonality_in[i % freq] / 100\n",
    "            y_hat_test_RNN[i - len(ts)] = y_hat_test_RNN[i - len(ts)] * seasonality_in[i % freq] / 100\n",
    "\n",
    "        # check if negative or extreme\n",
    "        for i in range(len(y_hat_test_MLP)):\n",
    "            if y_hat_test_MLP[i] < 0:\n",
    "                y_hat_test_MLP[i] = 0\n",
    "            if y_hat_test_RNN[i] < 0:\n",
    "                y_hat_test_RNN[i] = 0\n",
    "                \n",
    "            if y_hat_test_MLP[i] > (1000 * max(ts)):\n",
    "                y_hat_test_MLP[i] = max(ts)         \n",
    "            if y_hat_test_RNN[i] > (1000 * max(ts)):\n",
    "                y_hat_test_RNN[i] = max(ts)\n",
    "\n",
    "        x_train, y_train, x_test, y_test = split_into_train_test(ts, in_size, fh)\n",
    "\n",
    "        # Calculate errors\n",
    "        err_MLP_sMAPE.append(smape(y_test, y_hat_test_MLP))\n",
    "        err_RNN_sMAPE.append(smape(y_test, y_hat_test_RNN))\n",
    "        err_MLP_MASE.append(mase(ts[:-fh], y_test, y_hat_test_MLP, freq))\n",
    "        err_RNN_MASE.append(mase(ts[:-fh], y_test, y_hat_test_RNN, freq))\n",
    "\n",
    "        # memory handling\n",
    "        ker.clear_session()\n",
    "        tf.reset_default_graph()\n",
    "        gc.collect()\n",
    "\n",
    "        counter = counter + 1\n",
    "        #**********************************************************************\n",
    "        print(\"-------------TS ID: \", counter, \"-------------\")\n",
    "        print(\" sMAPE_MLP:\",err_MLP_sMAPE[-1], \" sMAPE_RNN:\",err_RNN_sMAPE[-1],\" MASE_MLP:\",err_MLP_MASE[-1],\" MASE_RNN:\",err_RNN_MASE[-1])\n",
    "        \n",
    "        p =[err_MLP_sMAPE[-1],err_RNN_sMAPE[-1],err_MLP_MASE[-1],err_RNN_MASE[-1]]\n",
    "        ds.loc[i] = p        \n",
    "        ds=ds.round(4)\n",
    "        if j==0:\n",
    "            ds.to_csv('out_yearly.csv', mode='a', header=False)\n",
    "        if j==1:\n",
    "            ds.to_csv('out_quarterly.csv', mode='a', header=False)\n",
    "        if j==2:\n",
    "            ds.to_csv('out_monthly.csv', mode='a', header=False)\n",
    "        if j==3:\n",
    "            ds.to_csv('out_weekly.csv', mode='a', header=False)\n",
    "        if j==4:\n",
    "            ds.to_csv('out_daily.csv', mode='a', header=False)\n",
    "        if j==5:\n",
    "            ds.to_csv('out_hourly.csv', mode='a', header=False)\n",
    "        #********************************************************************    \n",
    "    print(\"\\n\\n---------FINAL RESULTS---------\")\n",
    "    print(\"=============sMAPE=============\\n\")\n",
    "    print(\"#### MLP ####\\n\", np.mean(err_MLP_sMAPE), \"\\n\")\n",
    "    print(\"#### RNN ####\\n\", np.mean(err_RNN_sMAPE), \"\\n\")\n",
    "    print(\"==============MASE=============\")\n",
    "    print(\"#### MLP ####\\n\", np.mean(err_MLP_MASE), \"\\n\")\n",
    "    print(\"#### RNN ####\\n\", np.mean(err_RNN_MASE), \"\\n\")\n",
    "    return np.mean(err_MLP_sMAPE),np.mean(err_RNN_sMAPE),np.mean(err_MLP_MASE),np.mean(err_RNN_MASE)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_all():\n",
    "    \n",
    "    print(\"### Load of Dataset  ###\")\n",
    "    df_yearly = pd.read_csv(\"../data/Yearly-train.csv\", skiprows=0, index_col =0)\n",
    "    df_quaterly = pd.read_csv(\"../data/Quarterly-train.csv\", skiprows=0, index_col =0)\n",
    "    df_monthly = pd.read_csv(\"../data/Monthly-train.csv\", skiprows=0, index_col =0)\n",
    "    df_weekly = pd.read_csv(\"../data/Weekly-train.csv\", skiprows=0, index_col =0)\n",
    "    df_daily = pd.read_csv(\"../data/Daily-train.csv\", skiprows=0, index_col =0)\n",
    "    df_hourly = pd.read_csv(\"../data/Hourly-train.csv\", skiprows=0, index_col =0)\n",
    "    \n",
    "    X_train, X_test = train_test_split(data, test_size=0.02, random_state=RANDOM_SEED)\n",
    "    \n",
    "    \n",
    "    D=[]\n",
    "    D.append(df_yearly)\n",
    "    D.append(df_quaterly)\n",
    "    D.append(df_monthly)\n",
    "    D.append(df_weekly)\n",
    "    D.append(df_daily)\n",
    "    D.append(df_hourly)\n",
    "    \n",
    "    columnsname= [\"Data_Type\",\"sMape MLP\",\"sMape RNN\",\"Mase MLP\",\"Mase RNN\"]\n",
    "    ds = pd.DataFrame(columns=columnsname )\n",
    "    ds.to_csv('outputM4.csv')\n",
    "    \n",
    "    \n",
    "    for i in range (len(D)):\n",
    "        if i==0:\n",
    "            print( \"*** Beginn of yearly dataset ***\")\n",
    "            a,b,c,d = main(D[i],6,1,i)\n",
    "            p= [\"Yearly_data\",a,b,c,d]\n",
    "            ds.iloc[i]= p\n",
    "            ds=ds.round(4)\n",
    "            ds.to_csv('outpoutM4.csv', mode='a', header=False)\n",
    "        if i==1:\n",
    "            print( \"*** Beginn of Quarterly dataset ***\")\n",
    "            a,b,c,d = main(D[i],8,4,i)\n",
    "            p= [\"Quarterly_data\",a,b,c,d]\n",
    "            ds.iloc[i]= p\n",
    "            ds=ds.round(4)\n",
    "            ds.to_csv('outpoutM4.csv', mode='a', header=False)\n",
    "        if i==2:\n",
    "            print( \"*** Beginn of Monthly dataset ***\")\n",
    "            a,b,c,d = main(D[i],18,12,i)\n",
    "            p= [\"Monthly_data\",a,b,c,d]\n",
    "            ds.iloc[i]= p\n",
    "            ds=ds.round(4)\n",
    "            ds.to_csv('outpoutM4.csv', mode='a', header=False)\n",
    "        if i==3:\n",
    "            print( \"*** Beginn of Weekly dataset ***\")\n",
    "            a,b,c,d = main(D[i],13,1,i)\n",
    "            p= [\"Weekly_data\",a,b,c,d]\n",
    "            ds.iloc[i]= p\n",
    "            ds=ds.round(4)\n",
    "            ds.to_csv('outpoutM4.csv', mode='a', header=False)\n",
    "        if i==4:\n",
    "            print( \"*** Beginn of Daily dataset ***\")\n",
    "            a,b,c,d = main(D[i],14,1,i)\n",
    "            p= [\"Daily_data\",a,b,c,d]\n",
    "            ds.iloc[i]= p\n",
    "            ds=ds.round(4)\n",
    "            ds.to_csv('outpoutM4.csv', mode='a', header=False)\n",
    "        if i==5:\n",
    "            print( \"*** Beginn of Hourly dataset ***\")\n",
    "            a,b,c,d = main(D[i],48,24,i)\n",
    "            p= [\"Hourly_data\",a,b,c,d]\n",
    "            ds.iloc[i]= p\n",
    "            ds=ds.round(4)\n",
    "            ds.to_csv('outputM4.csv', mode='a', header=False)\n",
    "    print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Load of Dataset  ###\n",
      "*** Beginn of yearly dataset ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/anaconda3/envs/jupyter/lib/python3.6/site-packages/ipykernel_launcher.py:82: FutureWarning: pd.rolling_mean is deprecated for Series and will be removed in a future version, replace with \n",
      "\tSeries.rolling(window=1,center=True).mean()\n",
      "/home/jupyter/anaconda3/envs/jupyter/lib/python3.6/site-packages/numpy/core/fromnumeric.py:52: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n",
      "  return getattr(obj, method)(*args, **kwds)\n",
      "/home/jupyter/anaconda3/envs/jupyter/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------TS ID:  1 -------------\n",
      " sMAPE_MLP: 0.10531365684804488  sMAPE_RNN: 0.09547596333707854  MASE_MLP: 7.382686578195777  MASE_RNN: 6.666194662058728\n",
      "-------------TS ID:  2 -------------\n",
      " sMAPE_MLP: 0.19690236155452553  sMAPE_RNN: 0.20485200788894808  MASE_MLP: 1.1419663364148105  MASE_RNN: 1.1813237395877547\n",
      "-------------TS ID:  3 -------------\n",
      " sMAPE_MLP: 0.15135493334352856  sMAPE_RNN: 0.15088102051276175  MASE_MLP: 6.886722993060876  MASE_RNN: 6.866131851230425\n",
      "-------------TS ID:  4 -------------\n",
      " sMAPE_MLP: 0.1455145475285837  sMAPE_RNN: 0.14248781456562623  MASE_MLP: 6.841531656773988  MASE_RNN: 6.6922694052419365\n",
      "-------------TS ID:  5 -------------\n",
      " sMAPE_MLP: 0.10921279996285528  sMAPE_RNN: 0.09937615506400947  MASE_MLP: 4.6721794634231175  MASE_RNN: 4.228635902189265\n",
      "-------------TS ID:  6 -------------\n",
      " sMAPE_MLP: 0.17474525721815795  sMAPE_RNN: 0.17497816452062834  MASE_MLP: 7.897580580619153  MASE_RNN: 7.921933404474266\n",
      "-------------TS ID:  7 -------------\n",
      " sMAPE_MLP: 0.1495866341386651  sMAPE_RNN: 0.1458971293460009  MASE_MLP: 10.366360695908075  MASE_RNN: 10.101694017261075\n",
      "-------------TS ID:  8 -------------\n",
      " sMAPE_MLP: 0.03760907895488567  sMAPE_RNN: 0.03629347246335742  MASE_MLP: 3.123501068821449  MASE_RNN: 3.0125189415701947\n",
      "-------------TS ID:  9 -------------\n",
      " sMAPE_MLP: 0.05480874616607743  sMAPE_RNN: 0.053093971804723444  MASE_MLP: 7.14201925114858  MASE_RNN: 6.9147423933961525\n",
      "-------------TS ID:  10 -------------\n",
      " sMAPE_MLP: 0.05093514356621417  sMAPE_RNN: 0.05397962208833398  MASE_MLP: 7.107307456520954  MASE_RNN: 7.541048171702277\n",
      "-------------TS ID:  11 -------------\n",
      " sMAPE_MLP: 0.046909448239532164  sMAPE_RNN: 0.04680276589290269  MASE_MLP: 7.169842683347462  MASE_RNN: 7.153291592879849\n",
      "-------------TS ID:  12 -------------\n",
      " sMAPE_MLP: 0.11370645401109936  sMAPE_RNN: 0.11338811608423295  MASE_MLP: 7.29589519458177  MASE_RNN: 7.273299465358136\n",
      "-------------TS ID:  13 -------------\n",
      " sMAPE_MLP: 0.18805804734500509  sMAPE_RNN: 0.18452505314770384  MASE_MLP: 7.442407630884357  MASE_RNN: 7.305866241953668\n",
      "-------------TS ID:  14 -------------\n",
      " sMAPE_MLP: 0.18772506477745218  sMAPE_RNN: 0.13700880459559464  MASE_MLP: 6.4694445709406345  MASE_RNN: 4.866811629563198\n",
      "-------------TS ID:  15 -------------\n",
      " sMAPE_MLP: 0.20957010613672764  sMAPE_RNN: 0.17195385214660108  MASE_MLP: 6.406254166959709  MASE_RNN: 5.207797649173074\n",
      "-------------TS ID:  16 -------------\n",
      " sMAPE_MLP: 0.14968290510463592  sMAPE_RNN: 0.13647404677475386  MASE_MLP: 6.758837082361506  MASE_RNN: 6.102608301055215\n",
      "-------------TS ID:  17 -------------\n",
      " sMAPE_MLP: 0.18928980053130115  sMAPE_RNN: 0.1575614749712961  MASE_MLP: 6.785832114593809  MASE_RNN: 5.5261539704128095\n",
      "-------------TS ID:  18 -------------\n",
      " sMAPE_MLP: 0.15806085869023323  sMAPE_RNN: 0.12358648880291899  MASE_MLP: 6.875796993782679  MASE_RNN: 5.260920633463209\n",
      "-------------TS ID:  19 -------------\n",
      " sMAPE_MLP: 0.26488662105204225  sMAPE_RNN: 0.22600655935871397  MASE_MLP: 6.84796132794973  MASE_RNN: 5.839268323042883\n",
      "-------------TS ID:  20 -------------\n",
      " sMAPE_MLP: 0.10619474360399261  sMAPE_RNN: 0.10695235358124262  MASE_MLP: 3.439517788617286  MASE_RNN: 3.4688878569491286\n",
      "-------------TS ID:  21 -------------\n",
      " sMAPE_MLP: 0.15141318481882546  sMAPE_RNN: 0.13571956049530273  MASE_MLP: 4.775248598594503  MASE_RNN: 4.25976780211134\n",
      "-------------TS ID:  22 -------------\n",
      " sMAPE_MLP: 0.20650655384805505  sMAPE_RNN: 0.20562831468244677  MASE_MLP: 7.026446759169947  MASE_RNN: 7.016765751582146\n",
      "-------------TS ID:  23 -------------\n",
      " sMAPE_MLP: 0.061626991207957116  sMAPE_RNN: 0.11820771968449244  MASE_MLP: 2.0629721978654194  MASE_RNN: 3.8500854038543726\n",
      "-------------TS ID:  24 -------------\n",
      " sMAPE_MLP: 0.11682755956168894  sMAPE_RNN: 0.10504230848640318  MASE_MLP: 4.06276384516722  MASE_RNN: 3.6653079043023613\n",
      "-------------TS ID:  25 -------------\n",
      " sMAPE_MLP: 0.12690269361423176  sMAPE_RNN: 0.1199169679890935  MASE_MLP: 5.955246015479828  MASE_RNN: 5.638451145900171\n",
      "-------------TS ID:  26 -------------\n",
      " sMAPE_MLP: 0.18695775095951636  sMAPE_RNN: 0.13940697802825575  MASE_MLP: 6.466926046333913  MASE_RNN: 4.789970837612877\n",
      "-------------TS ID:  27 -------------\n",
      " sMAPE_MLP: 0.14701996090563854  sMAPE_RNN: 0.13860152693685016  MASE_MLP: 6.24751354269445  MASE_RNN: 5.89460965964941\n",
      "-------------TS ID:  28 -------------\n",
      " sMAPE_MLP: 0.1496096563344322  sMAPE_RNN: 0.12864661754785264  MASE_MLP: 6.364205325576526  MASE_RNN: 5.455811948119274\n",
      "-------------TS ID:  29 -------------\n",
      " sMAPE_MLP: 0.06402662450911695  sMAPE_RNN: 0.06343370104993855  MASE_MLP: 8.737093784560255  MASE_RNN: 8.654085048280782\n",
      "-------------TS ID:  30 -------------\n",
      " sMAPE_MLP: 0.1389583219086058  sMAPE_RNN: 0.13004278393796628  MASE_MLP: 6.871048952860016  MASE_RNN: 6.40835203613099\n",
      "-------------TS ID:  31 -------------\n",
      " sMAPE_MLP: 0.03533479983384414  sMAPE_RNN: 0.05024021240114727  MASE_MLP: 4.607061743036739  MASE_RNN: 6.616090736453415\n",
      "-------------TS ID:  32 -------------\n",
      " sMAPE_MLP: 0.06345186061409475  sMAPE_RNN: 0.06284890381096746  MASE_MLP: 8.110195936773803  MASE_RNN: 8.031003494853891\n",
      "-------------TS ID:  33 -------------\n",
      " sMAPE_MLP: 0.08203832391986043  sMAPE_RNN: 0.0839576942095419  MASE_MLP: 6.73258229871913  MASE_RNN: 6.889081237911028\n",
      "-------------TS ID:  34 -------------\n",
      " sMAPE_MLP: 0.05028895573785739  sMAPE_RNN: 0.0528099209917633  MASE_MLP: 5.325867235320603  MASE_RNN: 5.596972443416357\n",
      "-------------TS ID:  35 -------------\n",
      " sMAPE_MLP: 0.1051587056479882  sMAPE_RNN: 0.10432404007639023  MASE_MLP: 7.170958850843255  MASE_RNN: 7.112523881987704\n",
      "-------------TS ID:  36 -------------\n",
      " sMAPE_MLP: 0.043084191023589374  sMAPE_RNN: 0.04175973935202485  MASE_MLP: 7.354992612669063  MASE_RNN: 7.124432495969665\n",
      "-------------TS ID:  37 -------------\n",
      " sMAPE_MLP: 0.08178571932973992  sMAPE_RNN: 0.08015664252058728  MASE_MLP: 7.708481585741826  MASE_RNN: 7.549780950595239\n",
      "-------------TS ID:  38 -------------\n",
      " sMAPE_MLP: 0.37932254130094806  sMAPE_RNN: 0.358980013310279  MASE_MLP: 3.823619818668157  MASE_RNN: 3.546197100095693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/anaconda3/envs/jupyter/lib/python3.6/site-packages/ipykernel_launcher.py:78: FutureWarning: pd.rolling_mean is deprecated for Series and will be removed in a future version, replace with \n",
      "\tSeries.rolling(window=1,center=True).mean()\n",
      "/home/jupyter/anaconda3/envs/jupyter/lib/python3.6/site-packages/ipykernel_launcher.py:79: FutureWarning: pd.rolling_mean is deprecated for Series and will be removed in a future version, replace with \n",
      "\tSeries.rolling(window=2,center=True).mean()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------TS ID:  39 -------------\n",
      " sMAPE_MLP: 0.11381990156679032  sMAPE_RNN: 0.03882936900132927  MASE_MLP: 4.392960399108378  MASE_RNN: 1.5797597670830998\n",
      "-------------TS ID:  40 -------------\n",
      " sMAPE_MLP: 0.18919588833217493  sMAPE_RNN: 0.07157282113722481  MASE_MLP: 14.814590253071414  MASE_RNN: 6.4118215776030985\n",
      "-------------TS ID:  41 -------------\n",
      " sMAPE_MLP: 0.07286612724123288  sMAPE_RNN: 0.0662560109176321  MASE_MLP: 5.421663155122629  MASE_RNN: 5.283060246723318\n",
      "-------------TS ID:  42 -------------\n",
      " sMAPE_MLP: 0.06861521069988652  sMAPE_RNN: 0.08790611150736743  MASE_MLP: 3.876716727599316  MASE_RNN: 4.8676356792898865\n",
      "-------------TS ID:  43 -------------\n",
      " sMAPE_MLP: 0.055800015126354276  sMAPE_RNN: 0.07105554947789892  MASE_MLP: 2.928943181345116  MASE_RNN: 3.7112312512520034\n",
      "-------------TS ID:  44 -------------\n",
      " sMAPE_MLP: 0.04763973289517003  sMAPE_RNN: 0.08340008214905238  MASE_MLP: 2.734509536274948  MASE_RNN: 4.896923781960377\n",
      "-------------TS ID:  45 -------------\n",
      " sMAPE_MLP: 0.08720569954655445  sMAPE_RNN: 0.09728472369901019  MASE_MLP: 5.192937008463268  MASE_RNN: 5.822093480215008\n",
      "-------------TS ID:  46 -------------\n",
      " sMAPE_MLP: 0.06622016780016331  sMAPE_RNN: 0.12871960693780285  MASE_MLP: 3.7094265086005738  MASE_RNN: 7.3872215092210665\n",
      "-------------TS ID:  47 -------------\n",
      " sMAPE_MLP: 0.06620520291931441  sMAPE_RNN: 0.14111786132680884  MASE_MLP: 3.7123592945484076  MASE_RNN: 8.162635515653639\n",
      "-------------TS ID:  48 -------------\n",
      " sMAPE_MLP: 0.2656310817368402  sMAPE_RNN: 0.13701399188103555  MASE_MLP: 13.294550991613173  MASE_RNN: 6.370972701854368\n",
      "-------------TS ID:  49 -------------\n",
      " sMAPE_MLP: 0.09288194682385993  sMAPE_RNN: 0.08829989951667132  MASE_MLP: 4.093153016511266  MASE_RNN: 3.884297040365489\n",
      "-------------TS ID:  50 -------------\n",
      " sMAPE_MLP: 0.062971285583959  sMAPE_RNN: 0.0837963785425621  MASE_MLP: 4.440269690725218  MASE_RNN: 5.963772454652929\n",
      "-------------TS ID:  51 -------------\n",
      " sMAPE_MLP: 0.08228419864326146  sMAPE_RNN: 0.08498277615391103  MASE_MLP: 6.837968563084132  MASE_RNN: 7.0662740957841885\n",
      "-------------TS ID:  52 -------------\n",
      " sMAPE_MLP: 0.13594795341194688  sMAPE_RNN: 0.1659543792788483  MASE_MLP: 5.033213049597774  MASE_RNN: 6.266783549506936\n",
      "-------------TS ID:  53 -------------\n",
      " sMAPE_MLP: 0.3010972359335322  sMAPE_RNN: 0.22560480380150646  MASE_MLP: 20.54113563875414  MASE_RNN: 15.625668314927516\n",
      "-------------TS ID:  54 -------------\n",
      " sMAPE_MLP: 0.1682996639105164  sMAPE_RNN: 0.12148231975957823  MASE_MLP: 8.10178770258482  MASE_RNN: 5.530213728415847\n",
      "-------------TS ID:  55 -------------\n",
      " sMAPE_MLP: 0.15225399354114197  sMAPE_RNN: 0.13119233148690196  MASE_MLP: 7.134645658985342  MASE_RNN: 6.027245995559156\n",
      "-------------TS ID:  56 -------------\n",
      " sMAPE_MLP: 0.1922184313025825  sMAPE_RNN: 0.1581759074750364  MASE_MLP: 9.738489775998694  MASE_RNN: 7.688548167488025\n",
      "-------------TS ID:  57 -------------\n",
      " sMAPE_MLP: 0.10216456782498962  sMAPE_RNN: 0.17214797484784564  MASE_MLP: 4.41941205894492  MASE_RNN: 7.8739493698418705\n",
      "-------------TS ID:  58 -------------\n",
      " sMAPE_MLP: 0.06210540734529762  sMAPE_RNN: 0.09167964632139229  MASE_MLP: 2.011032230679641  MASE_RNN: 3.0200432850130285\n",
      "-------------TS ID:  59 -------------\n",
      " sMAPE_MLP: 0.05414515985709884  sMAPE_RNN: 0.06164603106510289  MASE_MLP: 4.120586280198724  MASE_RNN: 4.703573827144972\n",
      "-------------TS ID:  60 -------------\n",
      " sMAPE_MLP: 0.12726958244006328  sMAPE_RNN: 0.11606632788116862  MASE_MLP: 6.409883633161486  MASE_RNN: 5.819758652341284\n",
      "-------------TS ID:  61 -------------\n",
      " sMAPE_MLP: 0.08709090379666261  sMAPE_RNN: 0.0618723978691195  MASE_MLP: 3.47756306104874  MASE_RNN: 2.43522798051282\n",
      "-------------TS ID:  62 -------------\n",
      " sMAPE_MLP: 0.259905311434992  sMAPE_RNN: 0.5719100151970978  MASE_MLP: 4.29771257564459  MASE_RNN: 7.978880246764574\n",
      "-------------TS ID:  63 -------------\n",
      " sMAPE_MLP: 0.0760397991912465  sMAPE_RNN: 0.07478792304627789  MASE_MLP: 3.1525106070550057  MASE_RNN: 3.0952304697190556\n",
      "-------------TS ID:  64 -------------\n",
      " sMAPE_MLP: 0.09462617535637897  sMAPE_RNN: 0.08034577984993997  MASE_MLP: 2.7868813053087096  MASE_RNN: 2.3455024098653343\n",
      "-------------TS ID:  65 -------------\n",
      " sMAPE_MLP: 0.12126578465480924  sMAPE_RNN: 0.07782533182994997  MASE_MLP: 2.446139142680492  MASE_RNN: 1.5866016470729507\n",
      "-------------TS ID:  66 -------------\n",
      " sMAPE_MLP: 0.2177920740876245  sMAPE_RNN: 0.2290385838651512  MASE_MLP: 4.860834425933138  MASE_RNN: 5.192072365766715\n",
      "-------------TS ID:  67 -------------\n",
      " sMAPE_MLP: 0.08105179802568364  sMAPE_RNN: 0.1386099451460313  MASE_MLP: 4.765080259505325  MASE_RNN: 8.38933163094104\n",
      "-------------TS ID:  68 -------------\n",
      " sMAPE_MLP: 0.03262975970355223  sMAPE_RNN: 0.05873867970507438  MASE_MLP: 1.8750828189845048  MASE_RNN: 3.4820111267373353\n",
      "-------------TS ID:  69 -------------\n",
      " sMAPE_MLP: 0.20168125070819273  sMAPE_RNN: 0.19842117476556187  MASE_MLP: 6.300376207221496  MASE_RNN: 6.175988249801908\n",
      "-------------TS ID:  70 -------------\n",
      " sMAPE_MLP: 0.2679729141993347  sMAPE_RNN: 0.19203827354713057  MASE_MLP: 10.406911736501904  MASE_RNN: 7.182348476499235\n",
      "-------------TS ID:  71 -------------\n",
      " sMAPE_MLP: 0.26207882415782685  sMAPE_RNN: 0.09139625177479253  MASE_MLP: 6.650787862933181  MASE_RNN: 2.030127048936757\n",
      "-------------TS ID:  72 -------------\n",
      " sMAPE_MLP: 0.05144180527443021  sMAPE_RNN: 0.14433952286549076  MASE_MLP: 2.9202204823484608  MASE_RNN: 8.7440689289204\n",
      "-------------TS ID:  73 -------------\n",
      " sMAPE_MLP: 0.1785956758540339  sMAPE_RNN: 0.17481248753230041  MASE_MLP: 2.980495316517108  MASE_RNN: 2.9148189489527088\n",
      "-------------TS ID:  74 -------------\n",
      " sMAPE_MLP: 0.09242261584887664  sMAPE_RNN: 0.1548703647440986  MASE_MLP: 2.209018139607998  MASE_RNN: 3.8716342001188764\n",
      "-------------TS ID:  75 -------------\n",
      " sMAPE_MLP: 0.0814088966328562  sMAPE_RNN: 0.10573323146381992  MASE_MLP: 4.4880504218523605  MASE_RNN: 5.895699925273943\n",
      "-------------TS ID:  76 -------------\n",
      " sMAPE_MLP: 0.1001008194200015  sMAPE_RNN: 0.1010682321383289  MASE_MLP: 4.610514870466525  MASE_RNN: 4.664207073258738\n",
      "-------------TS ID:  77 -------------\n",
      " sMAPE_MLP: 0.06618175295569333  sMAPE_RNN: 0.046056089773894804  MASE_MLP: 3.31416050547036  MASE_RNN: 2.2613977008528314\n",
      "-------------TS ID:  78 -------------\n",
      " sMAPE_MLP: 0.12404174917608023  sMAPE_RNN: 0.05278497748214352  MASE_MLP: 8.431749007456181  MASE_RNN: 3.779565989302507\n",
      "-------------TS ID:  79 -------------\n",
      " sMAPE_MLP: 0.26649915457907  sMAPE_RNN: 0.19306304737115296  MASE_MLP: 13.21859995132633  MASE_RNN: 9.998319833319009\n",
      "-------------TS ID:  80 -------------\n",
      " sMAPE_MLP: 0.43642040011547806  sMAPE_RNN: 0.3862997468159082  MASE_MLP: 7.058021806120355  MASE_RNN: 6.123365223872343\n",
      "-------------TS ID:  81 -------------\n",
      " sMAPE_MLP: 0.06951790941035636  sMAPE_RNN: 0.09901841564328928  MASE_MLP: 4.6006511975474265  MASE_RNN: 6.766889418386455\n",
      "-------------TS ID:  82 -------------\n",
      " sMAPE_MLP: 0.14978370831143537  sMAPE_RNN: 0.15123743728248362  MASE_MLP: 7.032101943640731  MASE_RNN: 7.096854717714261\n",
      "-------------TS ID:  83 -------------\n",
      " sMAPE_MLP: 0.13435568944564313  sMAPE_RNN: 0.03587427521800766  MASE_MLP: 9.127651904230163  MASE_RNN: 2.475895554397106\n",
      "-------------TS ID:  84 -------------\n",
      " sMAPE_MLP: 0.043257471266896524  sMAPE_RNN: 0.016114911154336282  MASE_MLP: 4.486721240012354  MASE_RNN: 1.6552977747887188\n",
      "-------------TS ID:  85 -------------\n",
      " sMAPE_MLP: 0.10278876775903541  sMAPE_RNN: 0.09358491561487152  MASE_MLP: 1.1082899587163766  MASE_RNN: 1.0152619930956144\n",
      "-------------TS ID:  86 -------------\n",
      " sMAPE_MLP: 0.1767965509674564  sMAPE_RNN: 0.13447413932751784  MASE_MLP: 1.9290252139705855  MASE_RNN: 1.5042434119063088\n",
      "-------------TS ID:  87 -------------\n",
      " sMAPE_MLP: 0.20118874160196323  sMAPE_RNN: 0.18893868958541363  MASE_MLP: 4.760001216344652  MASE_RNN: 4.528690750722383\n",
      "-------------TS ID:  88 -------------\n",
      " sMAPE_MLP: 0.13559083768688376  sMAPE_RNN: 0.12349161581949213  MASE_MLP: 0.951152242715267  MASE_RNN: 0.864159458705357\n",
      "-------------TS ID:  89 -------------\n",
      " sMAPE_MLP: 0.39200966460911957  sMAPE_RNN: 0.3948620449191349  MASE_MLP: 3.779385406572413  MASE_RNN: 4.106017439743683\n",
      "-------------TS ID:  90 -------------\n",
      " sMAPE_MLP: 0.17604580291940497  sMAPE_RNN: 0.15927830460630485  MASE_MLP: 1.4616424354052042  MASE_RNN: 1.335702087255517\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------TS ID:  91 -------------\n",
      " sMAPE_MLP: 0.09272647304492548  sMAPE_RNN: 0.03393546802349806  MASE_MLP: 7.018524415853414  MASE_RNN: 2.498480513723273\n",
      "-------------TS ID:  92 -------------\n",
      " sMAPE_MLP: 0.2738499503653244  sMAPE_RNN: 0.2659867693342563  MASE_MLP: 1.0540153290563523  MASE_RNN: 1.0191358060266882\n",
      "-------------TS ID:  93 -------------\n",
      " sMAPE_MLP: 0.07908688540162766  sMAPE_RNN: 0.07995541026929247  MASE_MLP: 2.632301293918726  MASE_RNN: 2.6643584295697385\n",
      "-------------TS ID:  94 -------------\n",
      " sMAPE_MLP: 0.0118323515179718  sMAPE_RNN: 0.0176003143298208  MASE_MLP: 0.7057880605542561  MASE_RNN: 1.0552295091840038\n",
      "-------------TS ID:  95 -------------\n",
      " sMAPE_MLP: 0.01841070380564722  sMAPE_RNN: 0.010060439977374548  MASE_MLP: 1.6486315669852674  MASE_RNN: 0.8958414562657514\n",
      "-------------TS ID:  96 -------------\n",
      " sMAPE_MLP: 0.08273693530900152  sMAPE_RNN: 0.0815279135297354  MASE_MLP: 2.6602792915909155  MASE_RNN: 2.622445946653194\n",
      "-------------TS ID:  97 -------------\n",
      " sMAPE_MLP: 0.091715134610681  sMAPE_RNN: 0.07190305169977214  MASE_MLP: 6.2763766563816645  MASE_RNN: 4.959063322301321\n",
      "-------------TS ID:  98 -------------\n",
      " sMAPE_MLP: 0.12600202576720332  sMAPE_RNN: 0.06365014606245194  MASE_MLP: 3.8659937769968353  MASE_RNN: 2.0111052088406822\n",
      "-------------TS ID:  99 -------------\n",
      " sMAPE_MLP: 0.09766449312079079  sMAPE_RNN: 0.048003294024837044  MASE_MLP: 3.5065648891701007  MASE_RNN: 1.7628759898096074\n",
      "-------------TS ID:  100 -------------\n",
      " sMAPE_MLP: 0.051820576191414704  sMAPE_RNN: 0.053053500426273215  MASE_MLP: 1.3987971055106765  MASE_RNN: 1.4407290728699718\n",
      "-------------TS ID:  101 -------------\n",
      " sMAPE_MLP: 0.4268901849630673  sMAPE_RNN: 0.4124806857832896  MASE_MLP: 2.1381245630450416  MASE_RNN: 2.07769080080778\n",
      "-------------TS ID:  102 -------------\n",
      " sMAPE_MLP: 0.044022596270474675  sMAPE_RNN: 0.6613491324625822  MASE_MLP: 3.423426609355029  MASE_RNN: 53.18237457110627\n",
      "-------------TS ID:  103 -------------\n",
      " sMAPE_MLP: 0.18039219815784888  sMAPE_RNN: 0.06614587350268654  MASE_MLP: 1.6147881481085582  MASE_RNN: 0.561774328202734\n",
      "-------------TS ID:  104 -------------\n",
      " sMAPE_MLP: 0.10452604707883906  sMAPE_RNN: 0.13794021539770565  MASE_MLP: 2.1825662719044963  MASE_RNN: 2.8266345731893536\n",
      "-------------TS ID:  105 -------------\n",
      " sMAPE_MLP: 0.33969465878457744  sMAPE_RNN: 0.3443497751389137  MASE_MLP: 2.3082504893721643  MASE_RNN: 2.336818626189816\n",
      "-------------TS ID:  106 -------------\n",
      " sMAPE_MLP: 0.14495418312081662  sMAPE_RNN: 0.12159268433253555  MASE_MLP: 1.0552930708561619  MASE_RNN: 0.8965564794912995\n",
      "-------------TS ID:  107 -------------\n",
      " sMAPE_MLP: 0.028187128741345283  sMAPE_RNN: 0.07332879510431177  MASE_MLP: 0.4864744910960212  MASE_RNN: 1.2497792149195952\n",
      "-------------TS ID:  108 -------------\n",
      " sMAPE_MLP: 0.2510817820063411  sMAPE_RNN: 0.24985128949670923  MASE_MLP: 1.1616002236784189  MASE_RNN: 1.155476141243553\n",
      "-------------TS ID:  109 -------------\n",
      " sMAPE_MLP: 0.09875430502845724  sMAPE_RNN: 0.11637337223335392  MASE_MLP: 0.6067639759179025  MASE_RNN: 0.7084537099991665\n",
      "-------------TS ID:  110 -------------\n",
      " sMAPE_MLP: 0.05243121199058499  sMAPE_RNN: 0.043756285485723245  MASE_MLP: 0.9763055770996298  MASE_RNN: 0.8117724041753124\n",
      "-------------TS ID:  111 -------------\n",
      " sMAPE_MLP: 0.2724376983236958  sMAPE_RNN: 0.30018498897738405  MASE_MLP: 6.415281234868775  MASE_RNN: 7.196398207628043\n",
      "-------------TS ID:  112 -------------\n",
      " sMAPE_MLP: 0.08437809276577972  sMAPE_RNN: 0.08220423488741414  MASE_MLP: 0.942035496956219  MASE_RNN: 0.9173305372224251\n",
      "-------------TS ID:  113 -------------\n",
      " sMAPE_MLP: 0.03282068945254501  sMAPE_RNN: 0.035107004740196644  MASE_MLP: 2.495874378702815  MASE_RNN: 2.6718207997255488\n",
      "-------------TS ID:  114 -------------\n",
      " sMAPE_MLP: 0.13416213896889148  sMAPE_RNN: 0.13484827845804678  MASE_MLP: 1.2877283675952778  MASE_RNN: 1.2943797424510108\n",
      "-------------TS ID:  115 -------------\n",
      " sMAPE_MLP: 0.07491604689821092  sMAPE_RNN: 0.09231262765738964  MASE_MLP: 1.3547063665964307  MASE_RNN: 1.6568319756018568\n",
      "-------------TS ID:  116 -------------\n",
      " sMAPE_MLP: 0.14046947950213087  sMAPE_RNN: 0.14346117770982428  MASE_MLP: 2.413090161822049  MASE_RNN: 2.468151551991737\n",
      "-------------TS ID:  117 -------------\n",
      " sMAPE_MLP: 0.4337218825439048  sMAPE_RNN: 0.31099897442456653  MASE_MLP: 4.7788752065749485  MASE_RNN: 3.194302102275498\n",
      "-------------TS ID:  118 -------------\n",
      " sMAPE_MLP: 0.1923223072406097  sMAPE_RNN: 0.23231779086143592  MASE_MLP: 2.012090523505584  MASE_RNN: 2.5249932360289953\n",
      "-------------TS ID:  119 -------------\n",
      " sMAPE_MLP: 0.04406103274973175  sMAPE_RNN: 0.04332572882151444  MASE_MLP: 0.8103042707058674  MASE_RNN: 0.7964117205281129\n",
      "-------------TS ID:  120 -------------\n",
      " sMAPE_MLP: 0.17341323618533688  sMAPE_RNN: 0.15109410544944793  MASE_MLP: 1.954429692710041  MASE_RNN: 1.6800286973927063\n",
      "-------------TS ID:  121 -------------\n",
      " sMAPE_MLP: 0.42628190347236394  sMAPE_RNN: 0.2917641371164813  MASE_MLP: 3.6790203784986164  MASE_RNN: 2.3335427934151856\n",
      "-------------TS ID:  122 -------------\n",
      " sMAPE_MLP: 0.26110023964921464  sMAPE_RNN: 0.09137446252998405  MASE_MLP: 1.088102063831328  MASE_RNN: 0.32929760736507696\n",
      "-------------TS ID:  123 -------------\n",
      " sMAPE_MLP: 0.061962883116124606  sMAPE_RNN: 0.0665517127356554  MASE_MLP: 0.7374138535169923  MASE_RNN: 0.7878619710952492\n",
      "-------------TS ID:  124 -------------\n",
      " sMAPE_MLP: 0.38321491262556134  sMAPE_RNN: 0.37118336941826807  MASE_MLP: 0.7699777597338534  MASE_RNN: 0.7464799928069797\n",
      "-------------TS ID:  125 -------------\n",
      " sMAPE_MLP: 0.011349979402364166  sMAPE_RNN: 0.013312773660048698  MASE_MLP: 0.5263108939329739  MASE_RNN: 0.6169072294010008\n",
      "-------------TS ID:  126 -------------\n",
      " sMAPE_MLP: 0.07805243739202902  sMAPE_RNN: 0.14892102247470018  MASE_MLP: 0.6227800448458719  MASE_RNN: 1.2646130789930619\n",
      "-------------TS ID:  127 -------------\n",
      " sMAPE_MLP: 0.024375363885224318  sMAPE_RNN: 0.026176351065667253  MASE_MLP: 0.3459741637628403  MASE_RNN: 0.37108291023871376\n",
      "-------------TS ID:  128 -------------\n",
      " sMAPE_MLP: 0.024757808071006516  sMAPE_RNN: 0.023884632892701766  MASE_MLP: 1.3981192837439784  MASE_RNN: 1.3485483912993343\n",
      "-------------TS ID:  129 -------------\n",
      " sMAPE_MLP: 0.3187099144937248  sMAPE_RNN: 0.3211363321532024  MASE_MLP: 5.7389244220005144  MASE_RNN: 5.684757704651097\n",
      "-------------TS ID:  130 -------------\n",
      " sMAPE_MLP: 0.013965430714018548  sMAPE_RNN: 0.007047409119630442  MASE_MLP: 1.0037864612293372  MASE_RNN: 0.504935833134806\n",
      "-------------TS ID:  131 -------------\n",
      " sMAPE_MLP: 0.01472140589736201  sMAPE_RNN: 0.011995289387772765  MASE_MLP: 0.5714605873394959  MASE_RNN: 0.4668070707400468\n",
      "-------------TS ID:  132 -------------\n",
      " sMAPE_MLP: 0.019992508583845898  sMAPE_RNN: 0.006214864821032586  MASE_MLP: 1.0439340298762037  MASE_RNN: 0.3271349333460093\n",
      "-------------TS ID:  133 -------------\n",
      " sMAPE_MLP: 0.4321159856288113  sMAPE_RNN: 0.4121320507088522  MASE_MLP: 5.346433142695429  MASE_RNN: 5.190493274216011\n",
      "-------------TS ID:  134 -------------\n",
      " sMAPE_MLP: 0.057221365723027884  sMAPE_RNN: 0.07941788064636636  MASE_MLP: 2.779101005500328  MASE_RNN: 3.8953959827482896\n",
      "-------------TS ID:  135 -------------\n",
      " sMAPE_MLP: 0.2142980040193019  sMAPE_RNN: 0.13877280762111577  MASE_MLP: 4.4902948814250445  MASE_RNN: 2.7412768974797825\n",
      "-------------TS ID:  136 -------------\n",
      " sMAPE_MLP: 0.1151004400825893  sMAPE_RNN: 0.10675958718581248  MASE_MLP: 4.224081320814372  MASE_RNN: 3.930323218080345\n",
      "-------------TS ID:  137 -------------\n",
      " sMAPE_MLP: 0.02078913086420831  sMAPE_RNN: 0.07459324808660427  MASE_MLP: 1.1814120835491606  MASE_RNN: 4.3758182355883175\n",
      "-------------TS ID:  138 -------------\n",
      " sMAPE_MLP: 0.2416247247396335  sMAPE_RNN: 0.14917363977633283  MASE_MLP: 4.235158094942298  MASE_RNN: 2.4911677979514515\n",
      "-------------TS ID:  139 -------------\n",
      " sMAPE_MLP: 0.09736994541503889  sMAPE_RNN: 0.1011009243003496  MASE_MLP: 0.9862459974051414  MASE_RNN: 1.0256132959247481\n",
      "-------------TS ID:  140 -------------\n",
      " sMAPE_MLP: 0.12507785316681092  sMAPE_RNN: 0.10555606382076115  MASE_MLP: 5.234929446473907  MASE_RNN: 4.377074795486404\n",
      "-------------TS ID:  141 -------------\n",
      " sMAPE_MLP: 0.14401979950472596  sMAPE_RNN: 0.1802321584467991  MASE_MLP: 5.301520490481446  MASE_RNN: 6.817946576449922\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------TS ID:  142 -------------\n",
      " sMAPE_MLP: 0.2724843401502795  sMAPE_RNN: 0.2417338080074787  MASE_MLP: 5.58777624880154  MASE_RNN: 4.873348513249832\n",
      "-------------TS ID:  143 -------------\n",
      " sMAPE_MLP: 0.06643685536672209  sMAPE_RNN: 0.07634930334912869  MASE_MLP: 4.014051741307568  MASE_RNN: 4.594228138895814\n",
      "-------------TS ID:  144 -------------\n",
      " sMAPE_MLP: 0.091877634472061  sMAPE_RNN: 0.09165272400147684  MASE_MLP: 3.162012456268439  MASE_RNN: 3.153695936326765\n",
      "-------------TS ID:  145 -------------\n",
      " sMAPE_MLP: 0.1105230580994172  sMAPE_RNN: 0.12128103436919734  MASE_MLP: 3.415606756907104  MASE_RNN: 3.7732543278098927\n",
      "-------------TS ID:  146 -------------\n",
      " sMAPE_MLP: 0.29085358910628184  sMAPE_RNN: 0.13403003227986635  MASE_MLP: 5.198379182161353  MASE_RNN: 2.161034339072077\n",
      "-------------TS ID:  147 -------------\n",
      " sMAPE_MLP: 0.26163055156610926  sMAPE_RNN: 0.25178619740983976  MASE_MLP: 6.616351158584847  MASE_RNN: 6.335216571195006\n",
      "-------------TS ID:  148 -------------\n",
      " sMAPE_MLP: 0.12304842685853651  sMAPE_RNN: 0.12811051802761994  MASE_MLP: 5.832727759348771  MASE_RNN: 6.06858266845806\n",
      "-------------TS ID:  149 -------------\n",
      " sMAPE_MLP: 0.05109256501061807  sMAPE_RNN: 0.05391114784680384  MASE_MLP: 3.0153602785981706  MASE_RNN: 3.11417509235493\n",
      "-------------TS ID:  150 -------------\n",
      " sMAPE_MLP: 0.10490937754246556  sMAPE_RNN: 0.08923023234839422  MASE_MLP: 4.205500065937334  MASE_RNN: 3.5451565745394986\n",
      "-------------TS ID:  151 -------------\n",
      " sMAPE_MLP: 0.16194147533984002  sMAPE_RNN: 0.19675300583519958  MASE_MLP: 5.765767360208433  MASE_RNN: 7.115527044719013\n",
      "-------------TS ID:  152 -------------\n",
      " sMAPE_MLP: 0.10491567297477382  sMAPE_RNN: 0.2823787015157719  MASE_MLP: 2.8826602608544474  MASE_RNN: 6.897950612764743\n",
      "-------------TS ID:  153 -------------\n",
      " sMAPE_MLP: 0.14191762405419325  sMAPE_RNN: 0.18310532796535373  MASE_MLP: 1.9652223581385733  MASE_RNN: 2.493588143273791\n",
      "-------------TS ID:  154 -------------\n",
      " sMAPE_MLP: 0.35777248028668834  sMAPE_RNN: 0.4060569490286435  MASE_MLP: 9.541372358045479  MASE_RNN: 11.148965806484652\n",
      "-------------TS ID:  155 -------------\n",
      " sMAPE_MLP: 0.0541585127978603  sMAPE_RNN: 0.05777309641834497  MASE_MLP: 1.2694670992750965  MASE_RNN: 1.3535121513356316\n",
      "-------------TS ID:  156 -------------\n",
      " sMAPE_MLP: 0.02588453859091369  sMAPE_RNN: 0.10073986008032094  MASE_MLP: 1.4636495282850166  MASE_RNN: 5.984031882384244\n",
      "-------------TS ID:  157 -------------\n",
      " sMAPE_MLP: 0.10558502666268511  sMAPE_RNN: 0.09887356243111038  MASE_MLP: 3.762399882926499  MASE_RNN: 3.531752722057797\n",
      "-------------TS ID:  158 -------------\n",
      " sMAPE_MLP: 0.020618897430178553  sMAPE_RNN: 0.09180035125245163  MASE_MLP: 1.1689545571354427  MASE_RNN: 5.465374696672674\n",
      "-------------TS ID:  159 -------------\n",
      " sMAPE_MLP: 0.1623163578076409  sMAPE_RNN: 0.06031804239926528  MASE_MLP: 4.502029589691736  MASE_RNN: 1.6063851658846782\n",
      "-------------TS ID:  160 -------------\n",
      " sMAPE_MLP: 0.08300304550454789  sMAPE_RNN: 0.047630098804660154  MASE_MLP: 4.371062421651601  MASE_RNN: 2.436898936573923\n",
      "-------------TS ID:  161 -------------\n",
      " sMAPE_MLP: 0.27739835276768593  sMAPE_RNN: 0.18111004394563887  MASE_MLP: 9.557657160658968  MASE_RNN: 5.923863722669916\n",
      "-------------TS ID:  162 -------------\n",
      " sMAPE_MLP: 0.08710780847465115  sMAPE_RNN: 0.061859941340804386  MASE_MLP: 2.9556173926771585  MASE_RNN: 2.049876663533905\n",
      "-------------TS ID:  163 -------------\n",
      " sMAPE_MLP: 0.08013917557339806  sMAPE_RNN: 0.09361221207537555  MASE_MLP: 3.7268103698364836  MASE_RNN: 4.360214212340113\n",
      "-------------TS ID:  164 -------------\n",
      " sMAPE_MLP: 0.14279157539096854  sMAPE_RNN: 0.10871438861752196  MASE_MLP: 6.9861231416622935  MASE_RNN: 5.22412791835252\n",
      "-------------TS ID:  165 -------------\n",
      " sMAPE_MLP: 0.04628640952064156  sMAPE_RNN: 0.07137719613328847  MASE_MLP: 1.8159510457944472  MASE_RNN: 2.79602770312867\n",
      "-------------TS ID:  166 -------------\n",
      " sMAPE_MLP: 0.12664411686883198  sMAPE_RNN: 0.1786685105124384  MASE_MLP: 3.0831834600292063  MASE_RNN: 4.342089181542075\n",
      "-------------TS ID:  167 -------------\n",
      " sMAPE_MLP: 0.1023663690485403  sMAPE_RNN: 0.09733543436278315  MASE_MLP: 5.080047765356435  MASE_RNN: 4.821313989027821\n",
      "-------------TS ID:  168 -------------\n",
      " sMAPE_MLP: 0.16708696647684204  sMAPE_RNN: 0.16814026292644768  MASE_MLP: 5.3151126502785875  MASE_RNN: 5.352503955485123\n",
      "-------------TS ID:  169 -------------\n",
      " sMAPE_MLP: 0.10010335561437705  sMAPE_RNN: 0.09850109486915869  MASE_MLP: 4.671472598437909  MASE_RNN: 4.602127065774528\n",
      "-------------TS ID:  170 -------------\n",
      " sMAPE_MLP: 0.08005989815940068  sMAPE_RNN: 0.06836295058479562  MASE_MLP: 4.564583805540459  MASE_RNN: 3.8694864084824845\n",
      "-------------TS ID:  171 -------------\n",
      " sMAPE_MLP: 0.07824901979317762  sMAPE_RNN: 0.07734251269036822  MASE_MLP: 2.6144816105109996  MASE_RNN: 2.594250218732187\n",
      "-------------TS ID:  172 -------------\n",
      " sMAPE_MLP: 0.1075521273454071  sMAPE_RNN: 0.25761595548718424  MASE_MLP: 0.41602834676236733  MASE_RNN: 0.9053677959845193\n",
      "-------------TS ID:  173 -------------\n",
      " sMAPE_MLP: 0.06704432848043747  sMAPE_RNN: 0.08750870592266823  MASE_MLP: 2.5044220140757165  MASE_RNN: 3.2988226559675327\n",
      "-------------TS ID:  174 -------------\n",
      " sMAPE_MLP: 0.058784671986778586  sMAPE_RNN: 0.07499012957123409  MASE_MLP: 2.828241562210948  MASE_RNN: 3.626959026773481\n",
      "-------------TS ID:  175 -------------\n",
      " sMAPE_MLP: 0.04497635624970169  sMAPE_RNN: 0.04520363633637887  MASE_MLP: 1.1619341678483823  MASE_RNN: 1.1679678293423172\n",
      "-------------TS ID:  176 -------------\n",
      " sMAPE_MLP: 0.04916952043508887  sMAPE_RNN: 0.030627461675384927  MASE_MLP: 0.9930729129379947  MASE_RNN: 0.607819301363459\n",
      "-------------TS ID:  177 -------------\n",
      " sMAPE_MLP: 0.12369709940155249  sMAPE_RNN: 0.03835531003032665  MASE_MLP: 7.621745685027605  MASE_RNN: 2.4556322575392433\n",
      "-------------TS ID:  178 -------------\n",
      " sMAPE_MLP: 0.19545976436467197  sMAPE_RNN: 0.4092263820259763  MASE_MLP: 2.1717903763744095  MASE_RNN: 4.038514432925905\n",
      "-------------TS ID:  179 -------------\n",
      " sMAPE_MLP: 0.10713484253775928  sMAPE_RNN: 0.1277961408075113  MASE_MLP: 5.855453995785752  MASE_RNN: 7.055512878823322\n",
      "-------------TS ID:  180 -------------\n",
      " sMAPE_MLP: 0.10898357228268196  sMAPE_RNN: 0.07206400350905787  MASE_MLP: 4.418189338730093  MASE_RNN: 2.841741853286664\n",
      "-------------TS ID:  181 -------------\n",
      " sMAPE_MLP: 0.06550033216761983  sMAPE_RNN: 0.049004342587475054  MASE_MLP: 2.5466427430345737  MASE_RNN: 1.897999100442125\n",
      "-------------TS ID:  182 -------------\n",
      " sMAPE_MLP: 0.18926769231738058  sMAPE_RNN: 0.17788654844135798  MASE_MLP: 4.054764202864801  MASE_RNN: 3.8108910029484115\n",
      "-------------TS ID:  183 -------------\n",
      " sMAPE_MLP: 0.02606577779999944  sMAPE_RNN: 0.0597571536351624  MASE_MLP: 2.126538779433701  MASE_RNN: 4.988741517869698\n",
      "-------------TS ID:  184 -------------\n",
      " sMAPE_MLP: 0.07458658851425508  sMAPE_RNN: 0.07374238915010528  MASE_MLP: 6.967283984019802  MASE_RNN: 6.885843119174676\n",
      "-------------TS ID:  185 -------------\n",
      " sMAPE_MLP: 0.14298548015764426  sMAPE_RNN: 0.04745588683345541  MASE_MLP: 15.636367209613105  MASE_RNN: 4.929769672482056\n",
      "-------------TS ID:  186 -------------\n",
      " sMAPE_MLP: 0.07193164504834706  sMAPE_RNN: 0.06422042084396333  MASE_MLP: 9.372845963913147  MASE_RNN: 8.337345040321807\n",
      "-------------TS ID:  187 -------------\n",
      " sMAPE_MLP: 0.03893161082137237  sMAPE_RNN: 0.03641200115466679  MASE_MLP: 7.382414306863941  MASE_RNN: 6.898997627167715\n",
      "-------------TS ID:  188 -------------\n",
      " sMAPE_MLP: 0.09454420773906579  sMAPE_RNN: 0.046820639616325495  MASE_MLP: 15.431547447630098  MASE_RNN: 7.452921272755214\n",
      "-------------TS ID:  189 -------------\n",
      " sMAPE_MLP: 0.07621576725201054  sMAPE_RNN: 0.0918401481462325  MASE_MLP: 6.354385167907489  MASE_RNN: 7.712070985602554\n",
      "-------------TS ID:  190 -------------\n",
      " sMAPE_MLP: 0.21967503741005656  sMAPE_RNN: 0.1873153707530325  MASE_MLP: 0.8111112517352871  MASE_RNN: 0.6968626556769356\n",
      "-------------TS ID:  191 -------------\n",
      " sMAPE_MLP: 1.8613248775824924  sMAPE_RNN: 1.7467762824030117  MASE_MLP: 2.8460646934721856  MASE_RNN: 2.749340797305947\n",
      "-------------TS ID:  192 -------------\n",
      " sMAPE_MLP: 0.203648562401343  sMAPE_RNN: 0.13150886701200448  MASE_MLP: 2.3827478773807766  MASE_RNN: 1.4728645428001221\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------TS ID:  193 -------------\n",
      " sMAPE_MLP: 0.1797925558748137  sMAPE_RNN: 0.1652038632752884  MASE_MLP: 2.98891059521024  MASE_RNN: 2.717601054258173\n",
      "-------------TS ID:  194 -------------\n",
      " sMAPE_MLP: 0.11265376985826625  sMAPE_RNN: 0.12798413998706729  MASE_MLP: 2.214412706049253  MASE_RNN: 2.536495605607988\n",
      "-------------TS ID:  195 -------------\n",
      " sMAPE_MLP: 0.15223312090191213  sMAPE_RNN: 0.1390797169598144  MASE_MLP: 3.7203538901707156  MASE_RNN: 3.377123873781592\n",
      "-------------TS ID:  196 -------------\n",
      " sMAPE_MLP: 0.1882426727709011  sMAPE_RNN: 0.17899039302345462  MASE_MLP: 4.203433433209474  MASE_RNN: 3.971659348367221\n",
      "-------------TS ID:  197 -------------\n",
      " sMAPE_MLP: 0.14621190552119162  sMAPE_RNN: 0.15980786912338085  MASE_MLP: 1.2782465599644801  MASE_RNN: 1.3856880107904739\n",
      "-------------TS ID:  198 -------------\n",
      " sMAPE_MLP: 0.1615371348746385  sMAPE_RNN: 0.15204550091992056  MASE_MLP: 1.6870627722035845  MASE_RNN: 1.576869658084608\n",
      "-------------TS ID:  199 -------------\n",
      " sMAPE_MLP: 0.30744568839863234  sMAPE_RNN: 0.24301166402834007  MASE_MLP: 2.8020135278708547  MASE_RNN: 2.258313214513989\n",
      "-------------TS ID:  200 -------------\n",
      " sMAPE_MLP: 0.07142636377194635  sMAPE_RNN: 0.1287031343326468  MASE_MLP: 0.32577719528354415  MASE_RNN: 0.5707428785192236\n",
      "-------------TS ID:  201 -------------\n",
      " sMAPE_MLP: 0.034963338866472134  sMAPE_RNN: 0.12338939108799742  MASE_MLP: 0.5789136255494983  MASE_RNN: 1.7949483229047065\n",
      "-------------TS ID:  202 -------------\n",
      " sMAPE_MLP: 0.14301164637341518  sMAPE_RNN: 0.1420040079892878  MASE_MLP: 1.9763064995706179  MASE_RNN: 1.9620157989250826\n",
      "-------------TS ID:  203 -------------\n",
      " sMAPE_MLP: 0.25040338505849524  sMAPE_RNN: 0.1669157458199851  MASE_MLP: 0.7540559408194458  MASE_RNN: 0.5130520878879081\n",
      "-------------TS ID:  204 -------------\n",
      " sMAPE_MLP: 0.18986852541880342  sMAPE_RNN: 0.16975902006413135  MASE_MLP: 3.4054408977944703  MASE_RNN: 3.002267586158459\n",
      "-------------TS ID:  205 -------------\n",
      " sMAPE_MLP: 0.30778481761312276  sMAPE_RNN: 0.26960745462778285  MASE_MLP: 1.234750687138228  MASE_RNN: 1.0918775469083306\n",
      "-------------TS ID:  206 -------------\n",
      " sMAPE_MLP: 0.10800699375210625  sMAPE_RNN: 0.10940023634412771  MASE_MLP: 0.9838473613970699  MASE_RNN: 0.996634910023142\n",
      "-------------TS ID:  207 -------------\n",
      " sMAPE_MLP: 0.0959891957609224  sMAPE_RNN: 0.06320868460372085  MASE_MLP: 0.8134354202227442  MASE_RNN: 0.4994614298784951\n",
      "-------------TS ID:  208 -------------\n",
      " sMAPE_MLP: 0.11266438930694261  sMAPE_RNN: 0.12728559410836063  MASE_MLP: 2.1884732004434913  MASE_RNN: 2.4919946621899656\n",
      "-------------TS ID:  209 -------------\n",
      " sMAPE_MLP: 0.1068423472312361  sMAPE_RNN: 0.1021752664739603  MASE_MLP: 0.5910426391526656  MASE_RNN: 0.5659636044314829\n",
      "-------------TS ID:  210 -------------\n",
      " sMAPE_MLP: 0.3510929624119898  sMAPE_RNN: 0.3655565468993449  MASE_MLP: 2.811110476637237  MASE_RNN: 2.921693610281563\n",
      "-------------TS ID:  211 -------------\n",
      " sMAPE_MLP: 0.2517096061139159  sMAPE_RNN: 0.18065060125823398  MASE_MLP: 2.3717578830002335  MASE_RNN: 1.6272340359411517\n",
      "-------------TS ID:  212 -------------\n",
      " sMAPE_MLP: 0.11840845513092978  sMAPE_RNN: 0.06995938744173565  MASE_MLP: 0.7354783535215279  MASE_RNN: 0.4164557392086975\n",
      "-------------TS ID:  213 -------------\n",
      " sMAPE_MLP: 0.8879576932629916  sMAPE_RNN: 1.1739311727242554  MASE_MLP: 6.552793833911802  MASE_RNN: 11.784933875379627\n",
      "-------------TS ID:  214 -------------\n",
      " sMAPE_MLP: 0.4384391936657683  sMAPE_RNN: 0.43802421226393645  MASE_MLP: 3.0453656532010873  MASE_RNN: 3.0414469511590445\n",
      "-------------TS ID:  215 -------------\n",
      " sMAPE_MLP: 0.04968451377285238  sMAPE_RNN: 0.04943203318577463  MASE_MLP: 2.698250846168299  MASE_RNN: 2.6846501287036584\n",
      "-------------TS ID:  216 -------------\n",
      " sMAPE_MLP: 0.10186358673955286  sMAPE_RNN: 0.10258280556507943  MASE_MLP: 0.7430085262119069  MASE_RNN: 0.748333867443943\n",
      "-------------TS ID:  217 -------------\n",
      " sMAPE_MLP: 0.10623117595452149  sMAPE_RNN: 0.0843202245868943  MASE_MLP: 0.8354569205772568  MASE_RNN: 0.6537185223159999\n",
      "-------------TS ID:  218 -------------\n",
      " sMAPE_MLP: 0.23196353161353656  sMAPE_RNN: 0.13754259461878993  MASE_MLP: 2.00813089942557  MASE_RNN: 1.1966714299079697\n",
      "-------------TS ID:  219 -------------\n",
      " sMAPE_MLP: 0.20809113066103954  sMAPE_RNN: 0.16033122961678656  MASE_MLP: 3.463123150735733  MASE_RNN: 2.5797283082039693\n",
      "-------------TS ID:  220 -------------\n",
      " sMAPE_MLP: 0.07435445064250966  sMAPE_RNN: 0.07175807270212821  MASE_MLP: 2.2255373139363863  MASE_RNN: 2.1479366117623604\n",
      "-------------TS ID:  221 -------------\n",
      " sMAPE_MLP: 0.05628278670609945  sMAPE_RNN: 0.05024201852080241  MASE_MLP: 0.7160629050193763  MASE_RNN: 0.6461057945806157\n",
      "-------------TS ID:  222 -------------\n",
      " sMAPE_MLP: 0.11247372667107923  sMAPE_RNN: 0.1201329016966257  MASE_MLP: 1.1561798390743974  MASE_RNN: 1.2417079085829368\n",
      "-------------TS ID:  223 -------------\n",
      " sMAPE_MLP: 0.2365949112406244  sMAPE_RNN: 0.17026350270991283  MASE_MLP: 2.600507577847108  MASE_RNN: 1.914114021758723\n",
      "-------------TS ID:  224 -------------\n",
      " sMAPE_MLP: 0.05899254797025768  sMAPE_RNN: 0.12086139484981218  MASE_MLP: 0.7109666134831628  MASE_RNN: 1.2805523934348824\n",
      "-------------TS ID:  225 -------------\n",
      " sMAPE_MLP: 0.2331814848449291  sMAPE_RNN: 0.1790398358299582  MASE_MLP: 3.883566310517106  MASE_RNN: 2.9741058442603348\n",
      "-------------TS ID:  226 -------------\n",
      " sMAPE_MLP: 0.10979163198948756  sMAPE_RNN: 0.12282252770784359  MASE_MLP: 1.0486192545217594  MASE_RNN: 1.1677432457861225\n",
      "-------------TS ID:  227 -------------\n",
      " sMAPE_MLP: 0.1990683150563288  sMAPE_RNN: 0.20860134979525588  MASE_MLP: 3.6763788602840064  MASE_RNN: 3.8779775866331945\n",
      "-------------TS ID:  228 -------------\n",
      " sMAPE_MLP: 0.1712601784501816  sMAPE_RNN: 0.1395927932544214  MASE_MLP: 0.4748637860974032  MASE_RNN: 0.3918623735565436\n",
      "-------------TS ID:  229 -------------\n",
      " sMAPE_MLP: 1.9586877204275244  sMAPE_RNN: 1.6134024879628246  MASE_MLP: 1.0451913095612912  MASE_RNN: 0.9117839798919809\n",
      "-------------TS ID:  230 -------------\n",
      " sMAPE_MLP: 0.08428138687030395  sMAPE_RNN: 0.04855432238215109  MASE_MLP: 0.8667645798660424  MASE_RNN: 0.5025614360989753\n",
      "-------------TS ID:  231 -------------\n",
      " sMAPE_MLP: 0.20965010137932447  sMAPE_RNN: 0.18121025456402137  MASE_MLP: 3.341830680677556  MASE_RNN: 2.8311874936189443\n",
      "-------------TS ID:  232 -------------\n",
      " sMAPE_MLP: 0.19732758762222966  sMAPE_RNN: 0.059217093892119044  MASE_MLP: 2.4664860054584716  MASE_RNN: 0.701799805521133\n",
      "-------------TS ID:  233 -------------\n",
      " sMAPE_MLP: 0.0207842649421633  sMAPE_RNN: 0.015240761807390946  MASE_MLP: 0.7946241638200101  MASE_RNN: 0.5911115908520639\n",
      "-------------TS ID:  234 -------------\n",
      " sMAPE_MLP: 0.1540675226238251  sMAPE_RNN: 0.14884391664146712  MASE_MLP: 2.0967340930377794  MASE_RNN: 2.01766851729647\n",
      "-------------TS ID:  235 -------------\n",
      " sMAPE_MLP: 0.027836589100607736  sMAPE_RNN: 0.021773187347243695  MASE_MLP: 0.22378385639722942  MASE_RNN: 0.17402368533307677\n",
      "-------------TS ID:  236 -------------\n",
      " sMAPE_MLP: 0.20874218477092818  sMAPE_RNN: 0.20021222649232717  MASE_MLP: 1.9240985124625414  MASE_RNN: 1.85960819569533\n",
      "-------------TS ID:  237 -------------\n",
      " sMAPE_MLP: 0.08326921405648775  sMAPE_RNN: 0.04154555227013917  MASE_MLP: 1.432605208231692  MASE_RNN: 0.7069693175057158\n",
      "-------------TS ID:  238 -------------\n",
      " sMAPE_MLP: 0.21035059256042807  sMAPE_RNN: 0.19902573685126038  MASE_MLP: 1.9225111302697901  MASE_RNN: 1.8205342708037389\n",
      "-------------TS ID:  239 -------------\n",
      " sMAPE_MLP: 0.16263189902376338  sMAPE_RNN: 0.09735718843315695  MASE_MLP: 1.6753438179318332  MASE_RNN: 1.048966254020755\n",
      "-------------TS ID:  240 -------------\n",
      " sMAPE_MLP: 0.168856217423169  sMAPE_RNN: 0.09487263021732688  MASE_MLP: 6.746387144454262  MASE_RNN: 3.989566065151964\n",
      "-------------TS ID:  241 -------------\n",
      " sMAPE_MLP: 0.13297350758708895  sMAPE_RNN: 0.08577137819109405  MASE_MLP: 6.376158218989536  MASE_RNN: 4.266947179077094\n",
      "-------------TS ID:  242 -------------\n",
      " sMAPE_MLP: 0.04965805162245298  sMAPE_RNN: 0.11273429384392646  MASE_MLP: 1.6050093375317724  MASE_RNN: 3.8520755800181674\n",
      "-------------TS ID:  243 -------------\n",
      " sMAPE_MLP: 0.18983431057100164  sMAPE_RNN: 0.16448402934313214  MASE_MLP: 3.2172560936061565  MASE_RNN: 2.8126897786949727\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------TS ID:  244 -------------\n",
      " sMAPE_MLP: 0.02698408181267205  sMAPE_RNN: 0.09711695787681647  MASE_MLP: 1.539361135749997  MASE_RNN: 5.822116960583123\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-d987b7e5e73f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmain_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-24-c4ed9771ca21>\u001b[0m in \u001b[0;36mmain_all\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;34m\"*** Beginn of yearly dataset ***\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m             \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mD\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m             \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"Yearly_data\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0mds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-20-908ae8bcd0c8>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(data_all, fh, freq, j)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0;31m# RNN benchmark - Produce forecasts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m         \u001b[0my_hat_test_RNN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrnn_bench\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;31m# MLP benchmark - Produce forecasts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-16-d300adfe4eea>\u001b[0m in \u001b[0;36mrnn_bench\u001b[0;34m(x_train, y_train, x_test, fh, input_size)\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m     \u001b[0;31m# fit the model to the training data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0;31m# make predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/jupyter/lib/python3.6/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1000\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1001\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1002\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1003\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1004\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/envs/jupyter/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1703\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1704\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1705\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1707\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/envs/jupyter/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1234\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1236\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1237\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/jupyter/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2480\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2481\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2482\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2483\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2484\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/jupyter/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    903\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 905\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    906\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/jupyter/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1138\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1139\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1140\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1141\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1142\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/jupyter/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1321\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/jupyter/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1325\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/jupyter/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1310\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1311\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1312\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1314\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/jupyter/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1418\u001b[0m         return tf_session.TF_Run(\n\u001b[1;32m   1419\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1420\u001b[0;31m             status, run_metadata)\n\u001b[0m\u001b[1;32m   1421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1422\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "main_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyter",
   "language": "python",
   "name": "jupyter"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
